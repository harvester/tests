<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>harvester_e2e_tests.integrations.test_1_volumes API documentation</title>
<meta name="description" content="">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>harvester_e2e_tests.integrations.test_1_volumes</code></h1>
</header>
<section id="section-intro">
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.test_concurrent_volume_creation"><code class="name flex">
<span>def <span class="ident">test_concurrent_volume_creation</span></span>(<span>api_client, ubuntu_image, concurrent_count, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.p2
@pytest.mark.volumes
@pytest.mark.parametrize(&#34;concurrent_count&#34;, [3, 5])
def test_concurrent_volume_creation(api_client, ubuntu_image, concurrent_count, polling_for):
    &#34;&#34;&#34;
    Test concurrent volume creation to validate system stability
    1. Create multiple volumes simultaneously using ThreadPoolExecutor
    2. Verify all volumes are created successfully
    3. Check for race conditions or resource conflicts
    4. Validate each volume reaches Bound state independently
    5. Cleanup all volumes concurrently

    Validates:
    - API endpoint thread safety
    - Storage backend concurrency handling
    - Resource naming collision prevention
    - Longhorn concurrent provisioning
    &#34;&#34;&#34;
    from datetime import datetime

    volume_names = [f&#34;concurrent-vol-{i}-{int(datetime.now().timestamp())}&#34;
                    for i in range(concurrent_count)]
    created_volumes = []
    errors = []

    def create_single_volume(vol_name):
        try:
            spec = api_client.volumes.Spec(&#34;5Gi&#34;)  # Smaller size for faster creation
            code, data = api_client.volumes.create(vol_name, spec, image_id=ubuntu_image[&#39;id&#39;])

            if code == 201:
                # Wait for volume to be bound
                code, data = polling_for(
                    &#34;volume do created&#34;,
                    lambda c, d: 200 == c and d[&#39;status&#39;][&#39;phase&#39;] == &#39;Bound&#39;,
                    api_client.volumes.get,
                    vol_name
                )
                return {&#34;name&#34;: vol_name, &#34;success&#34;: True, &#34;data&#34;: data}
            else:
                return {&#34;name&#34;: vol_name, &#34;success&#34;: False,
                        &#34;error&#34;: f&#34;Creation failed: {code}, {data}&#34;}

        except Exception as e:
            return {&#34;name&#34;: vol_name, &#34;success&#34;: False, &#34;error&#34;: str(e)}

    # Create volumes concurrently
    with ThreadPoolExecutor(max_workers=concurrent_count) as executor:
        futures = [executor.submit(create_single_volume, name) for name in volume_names]

        for future in as_completed(futures):
            result = future.result()
            if result[&#34;success&#34;]:
                created_volumes.append(result[&#34;name&#34;])
            else:
                errors.append(result)

    # Validate results
    assert len(errors) == 0, f&#34;Concurrent creation errors: {errors}&#34;
    assert len(created_volumes) == concurrent_count, f&#34;Expected {concurrent_count}&#34; \
                                                     f&#34; volumes, created {len(created_volumes)}&#34;

    # Verify all volumes are properly created and accessible
    for vol_name in created_volumes:
        code, data = api_client.volumes.get(vol_name)
        assert 200 == code, f&#34;Volume {vol_name} not accessible: {code}&#34;
        assert data[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;, f&#34;Volume {vol_name} not bound: &#34; \
                                                   f&#34;{data[&#39;status&#39;][&#39;phase&#39;]}&#34;

    # Cleanup all volumes concurrently
    def cleanup_single_volume(vol_name):
        try:
            polling_for(&#34;volume do deleted&#34;,
                        lambda code, _: 404 == code, api_client.volumes.delete, vol_name)
            return True
        except Exception as e:
            print(f&#34;Cleanup error for {vol_name}: {e}&#34;)
            return False

    with ThreadPoolExecutor(max_workers=concurrent_count) as executor:
        cleanup_futures = [executor.submit(cleanup_single_volume, name)
                           for name in created_volumes]
        cleanup_results = [future.result() for future in as_completed(cleanup_futures)]

    assert all(cleanup_results), &#34;Some volumes failed to cleanup properly&#34;</code></pre>
</details>
<div class="desc"><p>Test concurrent volume creation to validate system stability
1. Create multiple volumes simultaneously using ThreadPoolExecutor
2. Verify all volumes are created successfully
3. Check for race conditions or resource conflicts
4. Validate each volume reaches Bound state independently
5. Cleanup all volumes concurrently</p>
<p>Validates:
- API endpoint thread safety
- Storage backend concurrency handling
- Resource naming collision prevention
- Longhorn concurrent provisioning</p></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.test_create_volume"><code class="name flex">
<span>def <span class="ident">test_create_volume</span></span>(<span>api_client, unique_name, ubuntu_image, create_as, source_type, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.p0
@pytest.mark.smoke
@pytest.mark.volumes
@pytest.mark.parametrize(&#34;create_as&#34;, [&#34;json&#34;, &#34;yaml&#34;])
@pytest.mark.parametrize(&#34;source_type&#34;, [&#34;New&#34;, &#34;VM Image&#34;])
def test_create_volume(api_client, unique_name, ubuntu_image, create_as, source_type, polling_for):
    &#34;&#34;&#34;
    1. Create a volume from image
    2. Create should respond with 201
    3. Wait for volume to create
    4. Failures should be at 0
    5. Get volume metadata
    6. Volume should not be in error or transitioning state
    7. ImageId should match what was used in create
    8. Delete volume
    9. Delete volume should reply 404 after delete
    Ref.
    &#34;&#34;&#34;
    image_id, storage_cls = None, None
    if source_type == &#34;VM Image&#34;:
        image_id, storage_cls = ubuntu_image[&#39;id&#39;], f&#34;longhorn-{ubuntu_image[&#39;display_name&#39;]}&#34;

    spec = api_client.volumes.Spec(&#34;10Gi&#34;, storage_cls)
    if create_as == &#39;yaml&#39;:
        kws = dict(headers={&#39;Content-Type&#39;: &#39;application/yaml&#39;}, json=None,
                   data=yaml.dump(spec.to_dict(unique_name, &#39;default&#39;, image_id=image_id)))
    else:
        kws = dict()
    code, data = api_client.volumes.create(unique_name, spec, image_id=image_id, **kws)
    assert 201 == code, (code, unique_name, data, image_id)

    polling_for(&#34;volume do created&#34;,
                lambda code, data: 200 == code and data[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;,
                api_client.volumes.get, unique_name)
    code2, data2 = api_client.images.get(ubuntu_image[&#39;display_name&#39;])
    # This grabs the failed count for the image
    failed: int = data2[&#39;status&#39;][&#39;failed&#39;]
    # This makes sure that the failures are 0
    assert failed &lt;= 3, &#39;Image failed more than 3 times&#39;

    code, data = api_client.volumes.get(unique_name)
    mdata, annotations = data[&#39;metadata&#39;], data[&#39;metadata&#39;][&#39;annotations&#39;]
    assert 200 == code, (code, data)
    assert unique_name == mdata[&#39;name&#39;], (code, data)
    # status
    assert not mdata[&#39;state&#39;][&#39;error&#39;], (code, data)
    assert not mdata[&#39;state&#39;][&#39;transitioning&#39;], (code, data)
    assert data[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;, (code, data)
    # source
    if source_type == &#34;VM Image&#34;:
        assert image_id == annotations[&#39;harvesterhci.io/imageId&#39;], (code, data)
    else:
        assert not annotations.get(&#39;harvesterhci.io/imageId&#39;), (code, data)
    # teardown
    polling_for(&#34;volume do deleted&#34;, lambda code, _: 404 == code,
                api_client.volumes.delete, unique_name)</code></pre>
</details>
<div class="desc"><ol>
<li>Create a volume from image</li>
<li>Create should respond with 201</li>
<li>Wait for volume to create</li>
<li>Failures should be at 0</li>
<li>Get volume metadata</li>
<li>Volume should not be in error or transitioning state</li>
<li>ImageId should match what was used in create</li>
<li>Delete volume</li>
<li>Delete volume should reply 404 after delete
Ref.</li>
</ol></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.test_create_volume_bad_checksum"><code class="name flex">
<span>def <span class="ident">test_create_volume_bad_checksum</span></span>(<span>api_client,<br>unique_name,<br>ubuntu_image_bad_checksum,<br>create_as,<br>source_type,<br>polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.p1
@pytest.mark.sanity
@pytest.mark.volumes
@pytest.mark.negative
@pytest.mark.parametrize(&#34;create_as&#34;, [&#34;json&#34;, &#34;yaml&#34;])
@pytest.mark.parametrize(&#34;source_type&#34;, [&#34;New&#34;, &#34;VM Image&#34;])
def test_create_volume_bad_checksum(api_client, unique_name, ubuntu_image_bad_checksum,
                                    create_as, source_type, polling_for):
    &#34;&#34;&#34;
    1. Create a volume from image with a bad checksum
    2. Create should respond with 201
    3. Wait for volume to create
    4. Wait for 4 failures in the volume fail status
    5. Failures should be set at 4
    6. Delete volume
    7. Delete volume should reply 404 after delete
    Ref. https://github.com/harvester/tests/issues/1121
    &#34;&#34;&#34;
    image_id, storage_cls = None, None
    if source_type == &#34;VM Image&#34;:
        image_id, storage_cls = ubuntu_image_bad_checksum[&#39;id&#39;], \
            f&#34;longhorn-{ubuntu_image_bad_checksum[&#39;display_name&#39;]}&#34;

    spec = api_client.volumes.Spec(&#34;10Gi&#34;, storage_cls)
    if create_as == &#39;yaml&#39;:
        kws = dict(headers={&#39;Content-Type&#39;: &#39;application/yaml&#39;}, json=None,
                   data=yaml.dump(spec.to_dict(unique_name, &#39;default&#39;, image_id=image_id)))
    else:
        kws = dict()
    code, data = api_client.volumes.create(unique_name, spec, image_id=image_id, **kws)
    assert 201 == code, (code, unique_name, data, image_id)

    polling_for(&#34;volume do created&#34;,
                lambda code, data: 200 == code and data[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;,
                api_client.volumes.get, unique_name)
    code2, data2 = api_client.images.get(ubuntu_image_bad_checksum[&#39;display_name&#39;])
    polling_for(&#34;failed to process sync file&#34;,
                lambda code2, data2: 200 == code2 and data2[&#39;status&#39;][&#39;failed&#39;] == 4,
                api_client.images.get, ubuntu_image_bad_checksum[&#39;display_name&#39;])

    # This grabs the failed count for the image
    code2, data2 = api_client.images.get(ubuntu_image_bad_checksum[&#39;display_name&#39;])
    failed: int = data2[&#39;status&#39;][&#39;failed&#39;]
    # This makes sure that the tests fails with bad checksum
    assert failed == 4, &#39;Image download correctly failed more than 3 times with bad checksum&#39;

    # teardown
    polling_for(&#34;volume do deleted&#34;, lambda code, _: 404 == code,
                api_client.volumes.delete, unique_name)</code></pre>
</details>
<div class="desc"><ol>
<li>Create a volume from image with a bad checksum</li>
<li>Create should respond with 201</li>
<li>Wait for volume to create</li>
<li>Wait for 4 failures in the volume fail status</li>
<li>Failures should be set at 4</li>
<li>Delete volume</li>
<li>Delete volume should reply 404 after delete
Ref. <a href="https://github.com/harvester/tests/issues/1121">https://github.com/harvester/tests/issues/1121</a></li>
</ol></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.test_create_volume_invalid_specifications"><code class="name flex">
<span>def <span class="ident">test_create_volume_invalid_specifications</span></span>(<span>api_client, gen_unique_name, invalid_spec)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.p1
@pytest.mark.negative
@pytest.mark.volumes
@pytest.mark.parametrize(&#34;invalid_spec&#34;, [
    {&#34;size&#34;: &#34;0Gi&#34;, &#34;error_msg&#34;: &#34;must be greater than zero&#34;},
    {&#34;size&#34;: &#34;-5Gi&#34;, &#34;error_msg&#34;: &#34;must be greater than zero&#34;},
    {&#34;size&#34;: &#34;invalid_size&#34;, &#34;error_msg&#34;: &#34;quantities must match&#34;},
    pytest.param(
        {&#34;size&#34;: &#34;999999Ti&#34;, &#34;error_msg&#34;: &#34;exceeds cluster capacity&#34;},
        marks=pytest.mark.xfail(
            reason=&#34;https://github.com/harvester/harvester/issues/9268&#34;)
    )],
    ids=[&#39;zero_size&#39;, &#39;negative_size&#39;, &#39;not_number&#39;, &#39;too_large_size&#39;])
def test_create_volume_invalid_specifications(api_client, gen_unique_name, invalid_spec):
    &#34;&#34;&#34;
    Negative testing for volume creation with invalid specifications
    1. Attempt to create volume with invalid size specification
    2. Verify appropriate error response (400 or 422)
    3. Ensure no volume resource is created
    4. Validate error message contains expected error information

    Test cases:
    - Zero size volumes should be rejected
    - Negative size volumes should be rejected
    - Invalid size format should be rejected
    - Excessively large volumes should be rejected
    &#34;&#34;&#34;
    spec = api_client.volumes.Spec(invalid_spec[&#34;size&#34;])

    unique_name = gen_unique_name()

    code, data = api_client.volumes.create(unique_name, spec)

    # Should fail with 400 (Bad Request) or 422 (Unprocessable Entity)
    assert code in [400, 422], f&#34;Expected error response, got {code}: {data}&#34;

    # Verify error message contains expected information
    error_message = str(data).lower()
    assert invalid_spec[&#34;error_msg&#34;].lower() in error_message, \
        f&#34;Expected &#39;{invalid_spec[&#39;error_msg&#39;]}&#39; in error: {data}&#34;

    # Ensure no volume was actually created
    code, data = api_client.volumes.get(unique_name)
    assert 404 == code, f&#34;Volume should not exist after failed creation: {code}, {data}&#34;</code></pre>
</details>
<div class="desc"><p>Negative testing for volume creation with invalid specifications
1. Attempt to create volume with invalid size specification
2. Verify appropriate error response (400 or 422)
3. Ensure no volume resource is created
4. Validate error message contains expected error information</p>
<p>Test cases:
- Zero size volumes should be rejected
- Negative size volumes should be rejected
- Invalid size format should be rejected
- Excessively large volumes should be rejected</p></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.test_delete_volume_when_exporting"><code class="name flex">
<span>def <span class="ident">test_delete_volume_when_exporting</span></span>(<span>api_client, unique_name, ubuntu_image, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.p1
@pytest.mark.sanity
@pytest.mark.negative
@pytest.mark.volumes
@pytest.mark.images
def test_delete_volume_when_exporting(api_client, unique_name, ubuntu_image, polling_for):
    # ref: https://github.com/harvester/tests/issues/1057

    # image id must follow RFC1123 which ends with alphanumeric char
    spec = api_client.volumes.Spec(&#39;10Gi&#39;)
    # create volume from image
    code, data = api_client.volumes.create(unique_name, spec, image_id=ubuntu_image[&#39;id&#39;])
    assert 201 == code, (code, data)
    polling_for(&#34;volume do created&#34;,
                lambda code, data: 200 == code and data[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;,
                api_client.volumes.get, unique_name)
    # export volume to image
    code, data = api_client.volumes.export(unique_name, unique_name, &#39;harvester-longhorn&#39;)
    assert 200 == code, (code, data)
    export_image = data[&#39;metadata&#39;][&#39;name&#39;]
    # delete volume while exporting
    code, data = api_client.volumes.delete(unique_name)
    assert 422 == code, (code, data)

    # teardown
    polling_for(&#34;image do deleted&#34;, lambda code, _: 404 == code,
                api_client.images.delete, export_image)
    polling_for(&#34;volume do deleted&#34;, lambda code, _: 404 == code,
                api_client.volumes.delete, unique_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.test_volume_resize_operations"><code class="name flex">
<span>def <span class="ident">test_volume_resize_operations</span></span>(<span>api_client, unique_name, ubuntu_image, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.p0
@pytest.mark.sanity
@pytest.mark.volumes
def test_volume_resize_operations(api_client, unique_name, ubuntu_image, polling_for):
    &#34;&#34;&#34;
    Test volume resize functionality
    Steps:
    1. Create initial volume with small size
    2. Resize volume to larger size
    3. Verify resize operation completes successfully
    4. Validate new size is reflected in volume specifications
    5. Test multiple resize operations
    &#34;&#34;&#34;
    initial_size = &#34;5Gi&#34;
    expanded_size = &#34;10Gi&#34;
    final_size = &#34;15Gi&#34;

    # Create initial volume
    spec = api_client.volumes.Spec(initial_size)
    code, data = api_client.volumes.create(unique_name, spec, image_id=ubuntu_image[&#39;id&#39;])
    assert 201 == code, f&#34;Initial volume creation failed: {code}, {data}&#34;

    # Wait for initial volume to be bound
    polling_for(&#34;initial volume created&#34;,
                lambda c, d: 200 == c and d[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;,
                api_client.volumes.get, unique_name)

    # Verify initial size
    code, data = api_client.volumes.get(unique_name)
    assert 200 == code, f&#34;Failed to get initial volume: {code}, {data}&#34;
    assert data[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] == initial_size

    # First resize: 5Gi -&gt; 10Gi
    # Get current volume state to obtain resourceVersion
    code, current_volume = api_client.volumes.get(unique_name)
    assert 200 == code, f&#34;Failed to get volume for resize: {code}, {current_volume}&#34;

    # Prepare update with resourceVersion and modified storage
    updated_volume = copy.deepcopy(current_volume)
    updated_volume[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] = expanded_size

    code, data = api_client.volumes.update(unique_name, updated_volume)
    assert 200 == code, f&#34;First resize operation failed: {code}, {data}&#34;

    # Wait for first resize to complete
    polling_for(&#34;first volume resize completed&#34;,
                lambda c, d: (200 == c and
                              d[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] == expanded_size),
                api_client.volumes.get, unique_name)

    # Verify first resize
    code, data = api_client.volumes.get(unique_name)
    assert 200 == code, f&#34;Failed to verify first resize: {code}, {data}&#34;
    assert data[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] == expanded_size
    assert data[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;, &#34;Volume should remain bound after resize&#34;

    # Second resize: 10Gi -&gt; 15Gi
    # Get updated volume state for second resize
    code, current_volume = api_client.volumes.get(unique_name)
    assert 200 == code, f&#34;Failed to get volume for second resize: {code}, {current_volume}&#34;

    updated_volume = copy.deepcopy(current_volume)
    updated_volume[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] = final_size

    code, data = api_client.volumes.update(unique_name, updated_volume)
    assert 200 == code, f&#34;Second resize operation failed: {code}, {data}&#34;

    # Wait for final resize to complete
    polling_for(&#34;final volume resize completed&#34;,
                lambda c, d: (200 == c and
                              d[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] == final_size),
                api_client.volumes.get, unique_name)

    # Final verification
    code, data = api_client.volumes.get(unique_name)
    assert 200 == code, f&#34;Failed to verify final resize: {code}, {data}&#34;
    assert data[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] == final_size
    assert data[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;, &#34;Volume should remain bound after final resize&#34;

    # Cleanup
    code, _ = api_client.volumes.delete(unique_name)
    assert code in [200, 202, 204], f&#34;Failed to initiate volume deletion: {code}&#34;

    polling_for(&#34;volume deleted&#34;, lambda code, _: 404 == code,
                api_client.volumes.get, unique_name)</code></pre>
</details>
<div class="desc"><p>Test volume resize functionality
Steps:
1. Create initial volume with small size
2. Resize volume to larger size
3. Verify resize operation completes successfully
4. Validate new size is reflected in volume specifications
5. Test multiple resize operations</p></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.test_volume_shrink_not_allowed"><code class="name flex">
<span>def <span class="ident">test_volume_shrink_not_allowed</span></span>(<span>api_client, unique_name, ubuntu_image, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.p2
@pytest.mark.volumes
@pytest.mark.negative
def test_volume_shrink_not_allowed(api_client, unique_name, ubuntu_image, polling_for):
    &#34;&#34;&#34;
    Test that volume shrinking is properly rejected
    Steps:
    1. Create volume with larger initial size
    2. Wait for volume to be bound and ready
    3. Attempt to resize volume to smaller size
    4. Verify operation fails with appropriate error
    5. Confirm volume size remains unchanged
    &#34;&#34;&#34;
    initial_size = &#34;5Gi&#34;
    shrink_size = &#34;1Gi&#34;

    # Create initial volume
    spec = api_client.volumes.Spec(initial_size)
    code, data = api_client.volumes.create(unique_name, spec, image_id=ubuntu_image[&#39;id&#39;])
    assert 201 == code, f&#34;Initial volume creation failed: {code}, {data}&#34;

    # Wait for volume to be bound
    polling_for(&#34;initial volume created&#34;,
                lambda c, d: 200 == c and d[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;,
                api_client.volumes.get, unique_name)

    # Verify initial size
    code, data = api_client.volumes.get(unique_name)
    assert 200 == code, f&#34;Failed to get initial volume: {code}, {data}&#34;
    assert data[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] == initial_size

    # Attempt to shrink volume
    code, current_volume = api_client.volumes.get(unique_name)
    assert 200 == code, f&#34;Failed to get volume for shrink test: {code}, {current_volume}&#34;

    updated_volume = copy.deepcopy(current_volume)
    updated_volume[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] = shrink_size

    code, data = api_client.volumes.update(unique_name, updated_volume)

    # Expect failure - common error codes for invalid operations
    expected_error_codes = [400, 422, 409, 403]
    assert code in expected_error_codes, f&#34;Volume shrink should fail, but got: {code}, {data}&#34;

    # Verify error message contains relevant information
    error_message = data.get(&#39;message&#39;, &#39;&#39;).lower()
    shrink_indicators = [&#39;not allowed&#39;, &#39;not supported&#39;, &#39;forbidden&#39;]

    message_found = any(indicator in error_message for indicator in shrink_indicators)
    assert message_found, f&#34;Error message should indicate shrinking issue. Got: {error_message}&#34;

    # Verify volume size unchanged after failed shrink
    code, unchanged_volume = api_client.volumes.get(unique_name)
    assert 200 == code, f&#34;Failed to verify volume after shrink attempt: {code}, {unchanged_volume}&#34;
    assert unchanged_volume[&#39;spec&#39;][&#39;resources&#39;][&#39;requests&#39;][&#39;storage&#39;] == initial_size, \
        &#34;Volume size should remain unchanged after failed shrink&#34;
    assert unchanged_volume[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;, \
        &#34;Volume should remain bound after failed shrink attempt&#34;

    # Cleanup
    code, _ = api_client.volumes.delete(unique_name)
    assert code in [200, 202, 204], f&#34;Failed to initiate volume deletion: {code}&#34;

    polling_for(&#34;volume deleted&#34;, lambda code, _: 404 == code,
                api_client.volumes.get, unique_name)</code></pre>
</details>
<div class="desc"><p>Test that volume shrinking is properly rejected
Steps:
1. Create volume with larger initial size
2. Wait for volume to be bound and ready
3. Attempt to resize volume to smaller size
4. Verify operation fails with appropriate error
5. Confirm volume size remains unchanged</p></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.ubuntu_image"><code class="name flex">
<span>def <span class="ident">ubuntu_image</span></span>(<span>api_client, unique_name, image_ubuntu, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture(scope=&#34;module&#34;)
def ubuntu_image(api_client, unique_name, image_ubuntu, polling_for):
    &#34;&#34;&#34;
    Generates a Ubuntu image

    1. Creates an image name based on unique_name
    2. Create the image based on URL
    3. Response for creation should be 201
    4. Loop while waiting for image to be created
    5. Yield the image with the namespace and name
    6. Delete the image
    7. The response for getting the image name should be 404 after deletion
    &#34;&#34;&#34;
    image_name = f&#34;img-{unique_name}&#34;
    code, data = api_client.images.create_by_url(image_name, image_ubuntu.url,
                                                 image_ubuntu.image_checksum)
    assert 201 == code, f&#34;Fail to create image\n{code}, {data}&#34;
    code, data = polling_for(&#34;image do created&#34;,
                             lambda c, d: c == 200 and d.get(&#39;status&#39;, {}).get(&#39;progress&#39;) == 100,
                             api_client.images.get, image_name)

    namespace = data[&#39;metadata&#39;][&#39;namespace&#39;]
    name = data[&#39;metadata&#39;][&#39;name&#39;]
    yield dict(ssh_user=image_ubuntu.ssh_user, id=f&#34;{namespace}/{name}&#34;, display_name=image_name)

    code, data = api_client.images.get(image_name)
    if 200 == code:
        code, data = api_client.images.delete(image_name)
        assert 200 == code, f&#34;Fail to cleanup image\n{code}, {data}&#34;
        polling_for(&#34;image do deleted&#34;,
                    lambda c, d: 404 == c,
                    api_client.images.get, image_name)</code></pre>
</details>
<div class="desc"><p>Generates a Ubuntu image</p>
<ol>
<li>Creates an image name based on unique_name</li>
<li>Create the image based on URL</li>
<li>Response for creation should be 201</li>
<li>Loop while waiting for image to be created</li>
<li>Yield the image with the namespace and name</li>
<li>Delete the image</li>
<li>The response for getting the image name should be 404 after deletion</li>
</ol></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.ubuntu_image_bad_checksum"><code class="name flex">
<span>def <span class="ident">ubuntu_image_bad_checksum</span></span>(<span>api_client, unique_name, image_ubuntu, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture(scope=&#34;module&#34;)
def ubuntu_image_bad_checksum(api_client, unique_name, image_ubuntu, polling_for):
    &#34;&#34;&#34;
    Generates a Ubuntu image with a bad sha512 checksum

    1. Creates an image name based on unique_name
    2. Create the image based on URL with a bad statically assigned checksum
    3. Response for creation should be 201
    4. Loop while waiting for image to be created
    5. Yield the image with the namespace and name
    6. Delete the image
    7. The response for getting the image name should be 404 after deletion
    &#34;&#34;&#34;

    image_name = f&#34;img-{unique_name + &#39;-badchecksum&#39;}&#34;
    # Random fake checksum to use in test
    fake_checksum = sha512(b&#39;not_a_valid_checksum&#39;).hexdigest()
    code, data = api_client.images.create_by_url(image_name, image_ubuntu.url, fake_checksum)
    assert 201 == code, f&#34;Fail to create image\n{code}, {data}&#34;
    code, data = polling_for(&#34;image do created&#34;,
                             lambda c, d: c == 200 and d.get(&#39;status&#39;, {}).get(&#39;progress&#39;) == 100,
                             api_client.images.get, image_name)
    namespace = data[&#39;metadata&#39;][&#39;namespace&#39;]
    name = data[&#39;metadata&#39;][&#39;name&#39;]
    yield dict(ssh_user=image_ubuntu.ssh_user, id=f&#34;{namespace}/{name}&#34;, display_name=image_name)
    code, data = api_client.images.get(image_name)
    if 200 == code:
        code, data = api_client.images.delete(image_name)
        assert 200 == code, f&#34;Fail to cleanup image\n{code}, {data}&#34;
        polling_for(&#34;image do deleted&#34;,
                    lambda c, d: 404 == c,
                    api_client.images.get, image_name)</code></pre>
</details>
<div class="desc"><p>Generates a Ubuntu image with a bad sha512 checksum</p>
<ol>
<li>Creates an image name based on unique_name</li>
<li>Create the image based on URL with a bad statically assigned checksum</li>
<li>Response for creation should be 201</li>
<li>Loop while waiting for image to be created</li>
<li>Yield the image with the namespace and name</li>
<li>Delete the image</li>
<li>The response for getting the image name should be 404 after deletion</li>
</ol></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.ubuntu_vm"><code class="name flex">
<span>def <span class="ident">ubuntu_vm</span></span>(<span>api_client, unique_name, ubuntu_image, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture(scope=&#34;class&#34;)
def ubuntu_vm(api_client, unique_name, ubuntu_image, polling_for):
    vm_name = f&#34;vm-{unique_name}&#34;

    vm_spec = api_client.vms.Spec(1, 2)
    vm_spec.add_image(vm_name, ubuntu_image[&#34;id&#34;])
    code, data = api_client.vms.create(vm_name, vm_spec)
    assert 201 == code, f&#34;Fail to create VM\n{code}, {data}&#34;
    code, data = polling_for(
        &#34;VM do created&#34;,
        lambda c, d: 200 == c and d.get(&#39;status&#39;, {}).get(&#39;printableStatus&#39;) == &#34;Running&#34;,
        api_client.vms.get, vm_name
    )

    volumes = list(filter(lambda vol: &#34;persistentVolumeClaim&#34; in vol,
                          data[&#34;spec&#34;][&#34;template&#34;][&#34;spec&#34;][&#34;volumes&#34;]))
    assert len(volumes) == 1
    yield data

    code, data = api_client.vms.get(vm_name)
    if 200 == code:
        code, data = api_client.vms.delete(vm_name)
        assert 200 == code, f&#34;Fail to cleanup VM\n{code}, {data}&#34;
        polling_for(&#34;VM do deleted&#34;,
                    lambda c, d: 404 == c,
                    api_client.vms.get, vm_name)

    vol_name = volumes[0][&#39;persistentVolumeClaim&#39;][&#39;claimName&#39;]
    code, data = api_client.volumes.get(vol_name)
    if 200 == code:
        api_client.volumes.delete(vol_name)
        assert 200 == code, f&#34;Fail to cleanup volume\n{code}, {data}&#34;
        polling_for(&#34;volume do deleted&#34;,
                    lambda c, d: 404 == c,
                    api_client.volumes.get, vol_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM"><code class="flex name class">
<span>class <span class="ident">TestVolumeWithVM</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.p0
@pytest.mark.sanity
@pytest.mark.volumes
@pytest.mark.virtualmachines
class TestVolumeWithVM:
    def pause_vm(self, api_client, ubuntu_vm, polling_for):
        vm_name = ubuntu_vm[&#39;metadata&#39;][&#39;name&#39;]
        code, data = api_client.vms.pause(vm_name)
        assert 204 == code, f&#34;Fail to pause VM\n{code}, {data}&#34;
        polling_for(&#34;VM do paused&#34;,
                    lambda c, d: d.get(&#39;status&#39;, {}).get(&#39;printableStatus&#39;) == &#34;Paused&#34;,
                    api_client.vms.get, vm_name)

    def stop_vm(self, api_client, ubuntu_vm, polling_for):
        vm_name = ubuntu_vm[&#39;metadata&#39;][&#39;name&#39;]
        code, data = api_client.vms.stop(vm_name)
        assert 204 == code, f&#34;Fail to stop VM\n{code}, {data}&#34;
        polling_for(&#34;VM do stopped&#34;,
                    lambda c, d: 404 == c,
                    api_client.vms.get_status, vm_name)

    def delete_vm(self, api_client, ubuntu_vm, polling_for):
        vm_name = ubuntu_vm[&#39;metadata&#39;][&#39;name&#39;]
        code, data = api_client.vms.delete(vm_name)
        assert 200 == code, f&#34;Fail to delete VM\n{code}, {data}&#34;
        polling_for(&#34;VM do deleted&#34;,
                    lambda c, d: 404 == c,
                    api_client.vms.get, vm_name)

    def test_delete_volume_on_existing_vm(self, api_client, ubuntu_image, ubuntu_vm, polling_for):
        &#34;&#34;&#34;
        1. Create a VM with volume
        2. Delete volume should reply 422
        3. Pause VM
        4. Delete volume should reply 422 too
        5. Stop VM
        6. Delete volume should reply 422 too
        Ref. https://github.com/harvester/tests/issues/905
        &#34;&#34;&#34;
        vol_name = (ubuntu_vm[&#34;spec&#34;][&#34;template&#34;][&#34;spec&#34;][&#34;volumes&#34;][0]
                             [&#39;persistentVolumeClaim&#39;][&#39;claimName&#39;])

        code, data = api_client.volumes.delete(vol_name)
        assert 422 == code, f&#34;Should fail to delete volume\n{code}, {data}&#34;

        self.pause_vm(api_client, ubuntu_vm, polling_for)
        code, data = api_client.volumes.delete(vol_name)
        assert 422 == code, f&#34;Should fail to delete volume\n{code}, {data}&#34;

        self.stop_vm(api_client, ubuntu_vm, polling_for)
        code, data = api_client.volumes.delete(vol_name)
        assert 422 == code, f&#34;Should fail to delete volume\n{code}, {data}&#34;

        # Check Volume
        code, data = api_client.volumes.get(vol_name)
        mdata, annotations = data[&#39;metadata&#39;], data[&#39;metadata&#39;][&#39;annotations&#39;]
        assert 200 == code, (code, data)
        assert mdata[&#39;name&#39;] == vol_name, (code, data)
        # status
        assert not mdata[&#39;state&#39;][&#39;error&#39;], (code, data)
        assert not mdata[&#39;state&#39;][&#39;transitioning&#39;], (code, data)
        assert data[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;, (code, data)
        # source
        assert ubuntu_image[&#34;id&#34;] == annotations[&#39;harvesterhci.io/imageId&#39;], (code, data)

    def test_delete_volume_on_deleted_vm(self, api_client, ubuntu_image, ubuntu_vm, polling_for):
        &#34;&#34;&#34;
        1. Create a VM with volume
        2. Delete VM but not volume
        3. Delete volume concurrently with VM
        4. VM should be deleted
        5. Volume should be deleted
        Ref. https://github.com/harvester/tests/issues/652
        &#34;&#34;&#34;
        vm_name = ubuntu_vm[&#39;metadata&#39;][&#39;name&#39;]
        vol_name = (ubuntu_vm[&#34;spec&#34;][&#34;template&#34;][&#34;spec&#34;][&#34;volumes&#34;][0]
                             [&#39;persistentVolumeClaim&#39;][&#39;claimName&#39;])

        api_client.vms.delete(vm_name)

        polling_for(&#34;Delete volume&#34;,
                    lambda c, d: 200 == c,
                    api_client.volumes.delete, vol_name)

        # Retry since VM is deleting
        polling_for(&#34;VM do deleted&#34;,
                    lambda c, d: 404 == c,
                    api_client.vms.get, vm_name)
        polling_for(&#34;Volume do deleted&#34;,
                    lambda c, d: 404 == c,
                    api_client.volumes.get, vol_name)</code></pre>
</details>
<div class="desc"></div>
<h3>Class variables</h3>
<dl>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.pytestmark"><code class="name">var <span class="ident">pytestmark</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.delete_vm"><code class="name flex">
<span>def <span class="ident">delete_vm</span></span>(<span>self, api_client, ubuntu_vm, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def delete_vm(self, api_client, ubuntu_vm, polling_for):
    vm_name = ubuntu_vm[&#39;metadata&#39;][&#39;name&#39;]
    code, data = api_client.vms.delete(vm_name)
    assert 200 == code, f&#34;Fail to delete VM\n{code}, {data}&#34;
    polling_for(&#34;VM do deleted&#34;,
                lambda c, d: 404 == c,
                api_client.vms.get, vm_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.pause_vm"><code class="name flex">
<span>def <span class="ident">pause_vm</span></span>(<span>self, api_client, ubuntu_vm, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pause_vm(self, api_client, ubuntu_vm, polling_for):
    vm_name = ubuntu_vm[&#39;metadata&#39;][&#39;name&#39;]
    code, data = api_client.vms.pause(vm_name)
    assert 204 == code, f&#34;Fail to pause VM\n{code}, {data}&#34;
    polling_for(&#34;VM do paused&#34;,
                lambda c, d: d.get(&#39;status&#39;, {}).get(&#39;printableStatus&#39;) == &#34;Paused&#34;,
                api_client.vms.get, vm_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.stop_vm"><code class="name flex">
<span>def <span class="ident">stop_vm</span></span>(<span>self, api_client, ubuntu_vm, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def stop_vm(self, api_client, ubuntu_vm, polling_for):
    vm_name = ubuntu_vm[&#39;metadata&#39;][&#39;name&#39;]
    code, data = api_client.vms.stop(vm_name)
    assert 204 == code, f&#34;Fail to stop VM\n{code}, {data}&#34;
    polling_for(&#34;VM do stopped&#34;,
                lambda c, d: 404 == c,
                api_client.vms.get_status, vm_name)</code></pre>
</details>
<div class="desc"></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.test_delete_volume_on_deleted_vm"><code class="name flex">
<span>def <span class="ident">test_delete_volume_on_deleted_vm</span></span>(<span>self, api_client, ubuntu_image, ubuntu_vm, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_delete_volume_on_deleted_vm(self, api_client, ubuntu_image, ubuntu_vm, polling_for):
    &#34;&#34;&#34;
    1. Create a VM with volume
    2. Delete VM but not volume
    3. Delete volume concurrently with VM
    4. VM should be deleted
    5. Volume should be deleted
    Ref. https://github.com/harvester/tests/issues/652
    &#34;&#34;&#34;
    vm_name = ubuntu_vm[&#39;metadata&#39;][&#39;name&#39;]
    vol_name = (ubuntu_vm[&#34;spec&#34;][&#34;template&#34;][&#34;spec&#34;][&#34;volumes&#34;][0]
                         [&#39;persistentVolumeClaim&#39;][&#39;claimName&#39;])

    api_client.vms.delete(vm_name)

    polling_for(&#34;Delete volume&#34;,
                lambda c, d: 200 == c,
                api_client.volumes.delete, vol_name)

    # Retry since VM is deleting
    polling_for(&#34;VM do deleted&#34;,
                lambda c, d: 404 == c,
                api_client.vms.get, vm_name)
    polling_for(&#34;Volume do deleted&#34;,
                lambda c, d: 404 == c,
                api_client.volumes.get, vol_name)</code></pre>
</details>
<div class="desc"><ol>
<li>Create a VM with volume</li>
<li>Delete VM but not volume</li>
<li>Delete volume concurrently with VM</li>
<li>VM should be deleted</li>
<li>Volume should be deleted
Ref. <a href="https://github.com/harvester/tests/issues/652">https://github.com/harvester/tests/issues/652</a></li>
</ol></div>
</dd>
<dt id="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.test_delete_volume_on_existing_vm"><code class="name flex">
<span>def <span class="ident">test_delete_volume_on_existing_vm</span></span>(<span>self, api_client, ubuntu_image, ubuntu_vm, polling_for)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_delete_volume_on_existing_vm(self, api_client, ubuntu_image, ubuntu_vm, polling_for):
    &#34;&#34;&#34;
    1. Create a VM with volume
    2. Delete volume should reply 422
    3. Pause VM
    4. Delete volume should reply 422 too
    5. Stop VM
    6. Delete volume should reply 422 too
    Ref. https://github.com/harvester/tests/issues/905
    &#34;&#34;&#34;
    vol_name = (ubuntu_vm[&#34;spec&#34;][&#34;template&#34;][&#34;spec&#34;][&#34;volumes&#34;][0]
                         [&#39;persistentVolumeClaim&#39;][&#39;claimName&#39;])

    code, data = api_client.volumes.delete(vol_name)
    assert 422 == code, f&#34;Should fail to delete volume\n{code}, {data}&#34;

    self.pause_vm(api_client, ubuntu_vm, polling_for)
    code, data = api_client.volumes.delete(vol_name)
    assert 422 == code, f&#34;Should fail to delete volume\n{code}, {data}&#34;

    self.stop_vm(api_client, ubuntu_vm, polling_for)
    code, data = api_client.volumes.delete(vol_name)
    assert 422 == code, f&#34;Should fail to delete volume\n{code}, {data}&#34;

    # Check Volume
    code, data = api_client.volumes.get(vol_name)
    mdata, annotations = data[&#39;metadata&#39;], data[&#39;metadata&#39;][&#39;annotations&#39;]
    assert 200 == code, (code, data)
    assert mdata[&#39;name&#39;] == vol_name, (code, data)
    # status
    assert not mdata[&#39;state&#39;][&#39;error&#39;], (code, data)
    assert not mdata[&#39;state&#39;][&#39;transitioning&#39;], (code, data)
    assert data[&#39;status&#39;][&#39;phase&#39;] == &#34;Bound&#34;, (code, data)
    # source
    assert ubuntu_image[&#34;id&#34;] == annotations[&#39;harvesterhci.io/imageId&#39;], (code, data)</code></pre>
</details>
<div class="desc"><ol>
<li>Create a VM with volume</li>
<li>Delete volume should reply 422</li>
<li>Pause VM</li>
<li>Delete volume should reply 422 too</li>
<li>Stop VM</li>
<li>Delete volume should reply 422 too
Ref. <a href="https://github.com/harvester/tests/issues/905">https://github.com/harvester/tests/issues/905</a></li>
</ol></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="harvester_e2e_tests.integrations" href="index.html">harvester_e2e_tests.integrations</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.test_concurrent_volume_creation" href="#harvester_e2e_tests.integrations.test_1_volumes.test_concurrent_volume_creation">test_concurrent_volume_creation</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.test_create_volume" href="#harvester_e2e_tests.integrations.test_1_volumes.test_create_volume">test_create_volume</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.test_create_volume_bad_checksum" href="#harvester_e2e_tests.integrations.test_1_volumes.test_create_volume_bad_checksum">test_create_volume_bad_checksum</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.test_create_volume_invalid_specifications" href="#harvester_e2e_tests.integrations.test_1_volumes.test_create_volume_invalid_specifications">test_create_volume_invalid_specifications</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.test_delete_volume_when_exporting" href="#harvester_e2e_tests.integrations.test_1_volumes.test_delete_volume_when_exporting">test_delete_volume_when_exporting</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.test_volume_resize_operations" href="#harvester_e2e_tests.integrations.test_1_volumes.test_volume_resize_operations">test_volume_resize_operations</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.test_volume_shrink_not_allowed" href="#harvester_e2e_tests.integrations.test_1_volumes.test_volume_shrink_not_allowed">test_volume_shrink_not_allowed</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.ubuntu_image" href="#harvester_e2e_tests.integrations.test_1_volumes.ubuntu_image">ubuntu_image</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.ubuntu_image_bad_checksum" href="#harvester_e2e_tests.integrations.test_1_volumes.ubuntu_image_bad_checksum">ubuntu_image_bad_checksum</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.ubuntu_vm" href="#harvester_e2e_tests.integrations.test_1_volumes.ubuntu_vm">ubuntu_vm</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM" href="#harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM">TestVolumeWithVM</a></code></h4>
<ul class="">
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.delete_vm" href="#harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.delete_vm">delete_vm</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.pause_vm" href="#harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.pause_vm">pause_vm</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.pytestmark" href="#harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.pytestmark">pytestmark</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.stop_vm" href="#harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.stop_vm">stop_vm</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.test_delete_volume_on_deleted_vm" href="#harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.test_delete_volume_on_deleted_vm">test_delete_volume_on_deleted_vm</a></code></li>
<li><code><a title="harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.test_delete_volume_on_existing_vm" href="#harvester_e2e_tests.integrations.test_1_volumes.TestVolumeWithVM.test_delete_volume_on_existing_vm">test_delete_volume_on_existing_vm</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
