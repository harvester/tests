<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Harvester Test Cases on Harvester manual test cases</title>
    <link>https://harvester.github.io/tests/</link>
    <description>Recent content in Harvester Test Cases on Harvester manual test cases</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://harvester.github.io/tests/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/47-verify-backup-restore-same-server/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/47-verify-backup-restore-same-server/</guid>
      <description></description>
    </item>
    
    <item>
      <title>01-Import existing Harvester clusters in Rancher</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/01-import-existing-harvester-in-rancher/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/01-import-existing-harvester-in-rancher/</guid>
      <description>Login rancher dashboard Navigate to Virtual Management Page Click import existing Copy the curl command  SSH to harvester master node (user: rancher) Execute the curl command to import harvester to rancher curl --insecure -sfL https://192.168.50.82/v3/import/{identifier}.yaml | kubectl apply -f - Run sudo chmod 775 /etc/rancher/rke2/rke2.yaml to solve the permission denied error Run curl command again, you should see the following successful import message namespace/cattle-system configured serviceaccount/cattle created clusterrolebinding.rbac.authorization.k8s.io/cattle-admin-binding created secret/cattle-credentials-413137f created clusterrole.</description>
    </item>
    
    <item>
      <title>02-Integrate to Rancher from Harvester settings</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/02-integrate-rancher-from-harvester-settings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/02-integrate-rancher-from-harvester-settings/</guid>
      <description>According to feature https://github.com/harvester/harvester/issues/1330
We will import harvester cluster to rancher cluster from harvester UI settings
Expected Results </description>
    </item>
    
    <item>
      <title>03-Manage VM in Downstream Harvster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/03-manage-vm-downstream-harvster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/03-manage-vm-downstream-harvster/</guid>
      <description>Prerequisite: Harvester already imported to Rancher Dashboard
 Open harvester from Virtualization Management page Open Virtual Machine page Create a single instance virtual machine in Virtual Machines page Create multiple 3 instances virtual machines in Virtual Machines page Access and check virtual machine details Edit cpu, memory and network of one virtual machine Try Stop, Restart and Migrate virtual machine Try Clone virtual machine Try Delete virtual machine  Expected Results  Can create a single instance vm correctly Can create multiple instances vm correctly Can diaply all virtual machine information Can change cpu, memory and network and retart vm correctly Can Stop, Restart and Migrate virtual machine correctly Can Clone virtual machine correctly Can Delete virtual machine correctly  </description>
    </item>
    
    <item>
      <title>04-Manage Node in Downstream Harvster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/04-manage-host-downstream-harvster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/04-manage-host-downstream-harvster/</guid>
      <description>Prerequisite: Harvester already imported to Rancher Dashboard
 Open harvester from Virtualization Management page Open Host page Access and check node details Edit node config, change network and add disk Try to Cordon and decordon node Enable and disable Maintenance mode  Expected Results  Can diaply all node&amp;rsquo;s information Can add disk to node correctly Can change network of node correctly Can Cordon and decordon node correctly Can enable and disable Maintenance mode  </description>
    </item>
    
    <item>
      <title>05-Manage Image in Downstream Harvster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/05-manage-image-volume-downstream-harvster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/05-manage-image-volume-downstream-harvster/</guid>
      <description>Prerequisite: Harvester already imported to Rancher Dashboard
 Open harvester from Virtualization Management page Open Images page Create an image from URL Create an image from file Delete created images  Expected Results  Can create an image from URL Can create an image from file Can create an image from file Can delete created images correctly  </description>
    </item>
    
    <item>
      <title>06-Manage Network in Downstream Harvster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/06-manage-network-in-downstream-harvster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/06-manage-network-in-downstream-harvster/</guid>
      <description>Prerequisite: Harvester already imported to Rancher Dashboard
 Open harvester from Virtualization Management page Open Network page Create an new virtual network Create a new virtual machine using the new virtual network Delete a virtual network  Expected Results  Can create an new virtual network Create create a new virtual machine using the new virtual network Virtual machine can retrieve ip address Can delete a virtual network  </description>
    </item>
    
    <item>
      <title>07-Add and grant project-owner user to harvester</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/07-rbac-add-grant-project-owner-user-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/07-rbac-add-grant-project-owner-user-harvester/</guid>
      <description> Open Users &amp;amp; Authentication Click Users and Create Create user name project-owner and set password Select Standard User in the Global permission Open harvester from Virtualization Management page Click Projects/Namespaces Edit config of default project   Search project-owner user Assign Owner role to it   Logout current user from Rancher Login with project-owner Open harvester from Virtualization Management page  Expected Results  Can create project-owner and set password Can assign Owner role to project-owner in default Can login correctly with project-owner Can manage all default project resources including host, virtual machines, volumes, VM and network  </description>
    </item>
    
    <item>
      <title>08-Add and grant project-readonly user to harvester</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/08-rbac-add-grant-project-readonly-user-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/08-rbac-add-grant-project-readonly-user-harvester/</guid>
      <description> Open Users &amp;amp; Authentication Click Users and Create Create user name project-readonly and set password Select Standard User in the Global permission Open harvester from Virtualization Management page Click Projects/Namespaces Edit config of default project   Search project-readonly user Assign Read Only role to it   Logout current user from Rancher Login with project-readonly Open harvester from Virtualization Management page  Expected Results  Can create project-readonly and set password Can assign Read Only role to project-readonly in default Can login correctly with project-readonly Can&amp;rsquo;t see Host page in harvester Can&amp;rsquo;t create or edit any resource including virtual machines, volumes, Images &amp;hellip;  </description>
    </item>
    
    <item>
      <title>09-Add and grant project-member user to harvester</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/09-rbac-add-grant-project-member-user-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/09-rbac-add-grant-project-member-user-harvester/</guid>
      <description> Open Users &amp;amp; Authentication Click Users and Create Create user name project-member and set password Select Standard User in the Global permission Open harvester from Virtualization Management page Click Projects/Namespaces Edit config of default project   Search project-member user Assign Member role to it   Logout current user from Rancher Login with project-member Open harvester from Virtualization Management page  Expected Results  Can create project-member and set password Can assign Member role to project-member in default Can login correctly with project-member Can&amp;rsquo;t see Host page in harvester Can&amp;rsquo;t create or edit any resource including virtual machines, volumes, Images &amp;hellip;  </description>
    </item>
    
    <item>
      <title>10-Add and grant project-custom user to harvester</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/10-rbacadd-grant-project-custom-user-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/10-rbacadd-grant-project-custom-user-harvester/</guid>
      <description> Open Users &amp;amp; Authentication Click Users and Create Create user name project-custom and set password Select Standard User in the Global permission Open harvester from Virtualization Management page Click Projects/Namespaces Edit config of default project   Search project-custom user Assign Custom role to it   Set Create Namespace, Manage Volumes and View Volumes Logout current user from Rancher Login with project-custom Open harvester from Virtualization Management page  Expected Results  Can create project-custom and set password Can assign Custom role to project-custom in default Can login correctly with project-custom Can do Create Namespace, Manage Volumes and View Volumes in default project  </description>
    </item>
    
    <item>
      <title>11-Create New Project in Harvester</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/11-create-project-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/11-create-project-harvester/</guid>
      <description> Open harvester from Virtualization Management page Click Projects/Namespaces Click Create Project Set CPU and Memory limit in Resource Quotas   Change view to testProject only   Create some images Create some volumes Create a virtual machine  Expected Results  Can creat project correctly in Projects/Namespaces page Can create images correctly Can create volumes correctly Can create virtual machine correctly  </description>
    </item>
    
    <item>
      <title>12-Create New Namespace in Harvester</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/12-create-namespace-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/12-create-namespace-harvester/</guid>
      <description> Open harvester from Virtualization Management page Click Projects/Namespaces Select the new project created in previous test case Click Create Namespace Set CPU and Memory limit in Container Resource Limit  Expected Results  Can creat new namepasce in correctly in create new project  </description>
    </item>
    
    <item>
      <title>13-Add and grant project-owner user to custom project</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/13-rbac-add-grant-project-owner-user-custom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/13-rbac-add-grant-project-owner-user-custom/</guid>
      <description> Open harvester from Virtualization Management page Click Projects/Namespaces Edit config of testProject project Search project-owner user Assign Owner role to it Logout current user from Rancher Login with project-owner Open harvester from Virtualization Management page Change view to testProject only  Expected Results  Can assign Owner role to project-owner in testProject project Can manage all testProject project resources including host, virtual machines, volumes, VM and network  </description>
    </item>
    
    <item>
      <title>14-Add and grant project-readonly user to custom project</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/14-rbac-add-grant-project-readonly-user-custom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/14-rbac-add-grant-project-readonly-user-custom/</guid>
      <description> Open harvester from Virtualization Management page Click Projects/Namespaces Edit config of testProject project Search project-readonly user Assign Read Only role to it Logout current user from Rancher Login with project-readonly Open harvester from Virtualization Management page Change view to testProject only  Expected Results  Can assign Read Only role to in testProject project Can login correctly with project-readonly Can&amp;rsquo;t see Host page in testProject only view Can&amp;rsquo;t create or edit any resource including virtual machines, volumes, Images &amp;hellip; in testProject only view  </description>
    </item>
    
    <item>
      <title>15-Add and grant project-member user to custom project</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/15-rbac-add-grant-project-member-user-custom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/15-rbac-add-grant-project-member-user-custom/</guid>
      <description> Open harvester from Virtualization Management page Click Projects/Namespaces Edit config of testProject project Search project-member user Assign Member role to it Logout current user from Rancher Login with project-member Open harvester from Virtualization Management page Change view to testProject only  Expected Results  Can assign Member role to project-member in testProject project Can login correctly with project-member Can&amp;rsquo;t see Host page in testProject project Can&amp;rsquo;t create or edit any resource including virtual machines, volumes, Images &amp;hellip; in testProject project  </description>
    </item>
    
    <item>
      <title>16-Add and grant project-custom user to custom project</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/16-rbac-add-grant-project-custom-user-custom/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/16-rbac-add-grant-project-custom-user-custom/</guid>
      <description> Open harvester from Virtualization Management page Click Projects/Namespaces Edit config of testProject project Search project-custom user Assign Custom role to it Set Create Namespace, Manage Volumes and View Volumes Logout current user from Rancher Login with project-custom Open harvester from Virtualization Management page Change view to testProject only  Expected Results  Can assign Custom role to project-custom in testProject project Can login correctly with project-custom Can do Create Namespace, Manage Volumes and View Volumes in testProject project  </description>
    </item>
    
    <item>
      <title>17-Delete Imported Harvester Cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/17-delete-imported-harvester-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/17-delete-imported-harvester-cluster/</guid>
      <description> Finish 01-Import existing Harvester clusters in Rancher Open Virtualization Management page Delete already imported harvester  Expected Results  Can delete imported harvester correctly  </description>
    </item>
    
    <item>
      <title>18-Delete Failed Imported Harvester Cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/18-delete-failed-imported-harvester-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/18-delete-failed-imported-harvester-cluster/</guid>
      <description> Make failure in 01-Import existing Harvester clusters in Rancher Open Virtualization Management page Delete already imported harvester  Expected Results  Can delete imported harvester correctly  </description>
    </item>
    
    <item>
      <title>19-Enable Harvester Node Driver</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/19-enable-harvester-node-driver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/19-enable-harvester-node-driver/</guid>
      <description> Open Cluster Management Click Drivers page and navigate to Node Drivers tab Search harvester Check Harvester and click Activate  Expected Results  Status displayed Activated  </description>
    </item>
    
    <item>
      <title>20-Create RKE1 Kubernetes Cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/20-create-rke1-kubernetes-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/20-create-rke1-kubernetes-cluster/</guid>
      <description>Click Cluster Management Click Cloud Credentials Click createa and select Harvester Input credential name Select existing cluster in the Imprted Cluster list Click Create   Expand RKE1 Configuration Add Template in Node template Select Harvester Select created cloud credential created Select default namespace Select ubuntu image Select network: vlan1 Provide SSH User: ubuntu   Provide template name, click create Open Cluster page, click Create Toggle RKE1 Provide cluster name Provide Name Prefix Select node template we just created Check etcd Check Control Panel   Click create  Expected Results  Provision RKE1 cluster successfully with Running status Can acccess RKE1 cluster to check all resources and services  Known issues This issue block the RKE 1 provisioning task</description>
    </item>
    
    <item>
      <title>21-Delete RKE1 Kubernetes Cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/21-delete-rke1-kubernetes-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/21-delete-rke1-kubernetes-cluster/</guid>
      <description> Open Cluster Management Check provisioned RKE1 cluster Click Delete from menu  Expected Results  Can remove RKE1 Cluster and disapper on Cluster page RKE1 Cluster will be removed from rancher menu under explore cluster RKE1 virtual machine should be also be removed from Harvester  </description>
    </item>
    
    <item>
      <title>22-Create RKE2 Kubernetes Cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/22-create-rke2-kubernetes-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/22-create-rke2-kubernetes-cluster/</guid>
      <description> Click Cluster Management Click Cloud Credentials Click createa and select Harvester Input credential name Select existing cluster in the Imprted Cluster list Click Create   Click Clusters Click Create Toggle RKE2/K3s Select Harvester Input Cluster Name Select default namespace Select ubuntu image Select network vlan1 Input SSH User: ubuntu Click Create   Wait for RKE2 cluster provisioning complete (~20min)  Expected Results  Provision RKE2 cluster successfully with Running status   Can acccess RKE2 cluster to check all resources and services  </description>
    </item>
    
    <item>
      <title>23-Delete RKE2 Kubernetes Cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/23-delete-rke2-kubernetes-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/23-delete-rke2-kubernetes-cluster/</guid>
      <description> Open Cluster Management Check provisioned RKE2 cluster Click Delete from menu  Expected Results  Can remove RKE2 Cluster and disapper on Cluster page RKE2 Cluster will be removed from rancher menu under explore cluster RKE2 virtual machine should be also be removed from Harvester  </description>
    </item>
    
    <item>
      <title>24-Delete RKE1 Kubernetes Cluster in Provisioning</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/24-delete-rke1-kubernetes-cluster-provisioning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/24-delete-rke1-kubernetes-cluster-provisioning/</guid>
      <description> Provision RKE1 Cluster Management When RKE1 cluster show Provisioning Click Delete from menu  Expected Results  Can remove RKE1 Cluster and disapper on Cluster page RKE1 Cluster will be removed from rancher menu under explore cluster RKE1 virtual machine should be also be removed from Harvester  </description>
    </item>
    
    <item>
      <title>25-Delete RKE1 Kubernetes Cluster in Failure</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/25-delete-rke1-kubernetes-cluster-failure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/25-delete-rke1-kubernetes-cluster-failure/</guid>
      <description> Provision RKE1 Cluster Management When RKE1 cluster displayed in Failure Click Delete from menu  Expected Results  Can remove RKE1 Cluster and disapper on Cluster page RKE1 Cluster will be removed from rancher menu under explore cluster RKE1 virtual machine should be also be removed from Harvester  </description>
    </item>
    
    <item>
      <title>26-Delete RKE2 Kubernetes Cluster in Provisioning</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/26-delete-rke2-kubernetes-cluster-provisioning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/26-delete-rke2-kubernetes-cluster-provisioning/</guid>
      <description> Provision RKE2 Cluster Management When RKE2 cluster show Provisioning Click Delete from menu  Expected Results  Can remove RKE2 Cluster and disapper on Cluster page RKE2 Cluster will be removed from rancher menu under explore cluster RKE2 virtual machine should be also be removed from Harvester  </description>
    </item>
    
    <item>
      <title>27-Delete RKE2 Kubernetes Cluster in Failure</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/27-delete-rke2-kubernetes-cluster-failure/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/27-delete-rke2-kubernetes-cluster-failure/</guid>
      <description> Provision RKE2 Cluster Management When RKE2 cluster displayed in Failure Click Delete from menu  Expected Results  Can remove RKE2 Cluster and disapper on Cluster page RKE2 Cluster will be removed from rancher menu under explore cluster RKE2 virtual machine should be also be removed from Harvester  </description>
    </item>
    
    <item>
      <title>28-Deploy Harvester cloud provider to RKE1 Cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/28-deploy-harvester-cloud-provider-to-rke1-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/28-deploy-harvester-cloud-provider-to-rke1-cluster/</guid>
      <description>1 Open Cluster Management page 1 Click Create 1 Expand RKE1 Configuration 1 Add Template in Node template 1 Select Harvester 1 Select created cloud credential created 1 Select default namespace 1 Select ubuntu image 1 Select network: vlan1
 Provide SSH User: ubuntu Provide template name, click create Open Cluster page, click Create Toggle RKE1 Provide cluster name Provide Name Prefix Select node template we just created Check etcd Check Control Panel Select External under Cloud Provider SSH to harvester cluster node Run the following command to generate add-on configuration  curl -sfL https://raw.</description>
    </item>
    
    <item>
      <title>29-Deploy Harvester cloud provider to RKE2 Cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/29-deploy-harvester-cloud-provider-to-rke2-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/29-deploy-harvester-cloud-provider-to-rke2-cluster/</guid>
      <description> Click Clusters Click Create Toggle RKE2/K3s Select Harvester Input Cluster Name Select default namespace Select ubuntu image Select network vlan1 Input SSH User: ubuntu Check alread set Harvester as cloud provider   Click Create Wait for RKE2 cluster provisioning complete (~20min)  Expected Results  Provision RKE2 cluster successfully with Running status   Can acccess RKE2 cluster to check all resources and services  </description>
    </item>
    
    <item>
      <title>30-Configure Harvester LoadBalancer service</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/30-configure-harvester-loadbalancer-service/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/30-configure-harvester-loadbalancer-service/</guid>
      <description>Prerequisite: Already provision RKE1/RKE2 cluster in previous test case
 Open Global Settings in hamburger menu Replace ui-dashboard-index to https://releases.rancher.com/harvester-ui/dashboard/latest/index.html Change ui-offline-preferred to Remote Refresh the current page (ctrl + r) Open provisioned RKE2 cluster from hamburger menu Drop down Service Discovery Click Services Click Create Select Load Balancer   Given service name Provide Listending port and Target port   Click Add-on Config Provide Health Check port Select dhcp as IPAM mode Provide Health Check Threshold Provide Health Check Failure Threshold Provide Health Check Period Provide Health Check Timeout Click Create button  Expected Results  Can create load balance service correctly   Can operate and foward workload as expected  </description>
    </item>
    
    <item>
      <title>31-Specify &#34;pool&#34; IPAM mode in LoadBalancer service</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/31-specify-pool-ipam-mode-loadbalancer-service/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/31-specify-pool-ipam-mode-loadbalancer-service/</guid>
      <description>Prerequisite: Already provision RKE1/RKE2 cluster in previous test case
 Open Global Settings in hamburger menu Replace ui-dashboard-index to https://releases.rancher.com/harvester-ui/dashboard/latest/index.html Change ui-offline-preferred to Remote Refresh the current page (ctrl + r) Open provisioned RKE2 cluster from hamburger menu Drop down Service Discovery Click Services Click Create Select Load Balancer   Given service name Provide Listending port and Target port   Click Add-on Config Provide Health Check port Select pool as IPAM mode Provide Health Check Threshold Provide Health Check Failure Threshold Provide Health Check Period Provide Health Check Timeout Click Create button  Expected Results  Can create load balance service correctly Can operate and foward workload as expected  </description>
    </item>
    
    <item>
      <title>32-Deploy Harvester CSI provider to RKE 1 Cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/32-deploy-harvester-csi-provider-to-rke1-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/32-deploy-harvester-csi-provider-to-rke1-cluster/</guid>
      <description>Open Cluster Management page Click Create Expand RKE1 Configuration Add Template in Node template Select Harvester Select created cloud credential created Select default namespace Select ubuntu image Select network: vlan1 Provide SSH User: ubuntu Provide template name, click create Open Cluster page, click Create Toggle RKE1 Provide cluster name Provide Name Prefix Select node template we just created Check etcd Check Control Panel SSH to harvester cluster node Run the following command to generate add-on configuration  .</description>
    </item>
    
    <item>
      <title>33-Deploy Harvester CSI provider to RKE 2 Cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/33-deploy-harvester-csi-provider-to-rke2-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/33-deploy-harvester-csi-provider-to-rke2-cluster/</guid>
      <description> Click Clusters Click Create Toggle RKE2/K3s Select Harvester Input Cluster Name Select default namespace Select ubuntu image Select network vlan1 Input SSH User: ubuntu Check alread set Harvester as cloud provider   Click Create Wait for RKE2 cluster provisioning complete (~20min)  Expected Results  Provision RKE2 cluster successfully with Running status   Can acccess RKE2 cluster to check all resources and services   Check CSI provider installed and configured on RKE2 cluster  </description>
    </item>
    
    <item>
      <title>34-Hot plug and unplug volumes in RKE1 cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/34-hotplug-unplug-volumes-in-rke1-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/34-hotplug-unplug-volumes-in-rke1-cluster/</guid>
      <description>Prerequisite: Already provisioned RKE1 cluster machine on Harvester
TBD
Expected Results TBD
Known issues This issue blocks the RKE 1 provisioning task
 #1519 Unable to create RKE1 cluster in rancher by node driver, shows &amp;ldquo;waiting for ssh to be available&amp;rdquo;  </description>
    </item>
    
    <item>
      <title>35-Hot plug and unplug volumes in RKE2 cluster</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/35-hotplug-unplug-volumes-in-rke2-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/35-hotplug-unplug-volumes-in-rke2-cluster/</guid>
      <description>Prerequisite: Already provisioned RKE2 cluster machine on Harvester
 Open RKE2 harvester from hamburger menu Open Storage Select PersistentVolumes Click Create Provide Name Select volume plugin to Local Open Custom Select harvester in Assign to Storage Class   Click create  Expected Results  Can create persistent volume correctly Can remove persistent volume correctly  </description>
    </item>
    
    <item>
      <title>36-Remove Harvester LoadBalancer service</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/36-remove-harvester-loadbalancer-service/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/36-remove-harvester-loadbalancer-service/</guid>
      <description> Open provisioned RKE2 cluster from hamburger menu Drop down Service Discovery Click Services Delete previous created load balancer service  Expected Results  Can remove load balance service correctly Service will be removed from assigned Apps  </description>
    </item>
    
    <item>
      <title>37-Import Online Harvester From the Airgapped Rancher</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/37-import-online-harvester-from-airgapped-rancher-copy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/37-import-online-harvester-from-airgapped-rancher-copy/</guid>
      <description>Environment Setup Setup the online harvester
 Use ipxe vagrant example to setup a 3 nodes cluster https://github.com/harvester/ipxe-examples/tree/main/vagrant-pxe-harvester Enable vlan on bond0 Now harvester dashboard page will out of work We can&amp;rsquo;t ssh to original assigned node ip We need to ssh to 192.168.0.30, 31, 32 instead Run ip a | grep bond0 get the {ip-of-bond0} Run the recover command Confirm default route by using ip r | grep default Wait for a while and access dashboard (it takes some time) Create ubuntu cloud image from URL Create virtual machine with name vlan1 and id: 1 Create virtual machine and assign vlan network, confirm can get ip address  Setup squid HTTP proxy server</description>
    </item>
    
    <item>
      <title>38-Import Airgapped Harvester From the Airgapped Rancher</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/38-import-airgapped-harvester-from-airgapped-rancher/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/38-import-airgapped-harvester-from-airgapped-rancher/</guid>
      <description>Environment Setup Setup the airgapped harvester
 Fetch ipxe vagrant example with new offline feature https://github.com/harvester/ipxe-examples/pull/32 Edit the setting.xml file Set offline: true Use ipxe vagrant example to setup a 3 nodes cluster Enable vlan on bond0 Now harvester dashboard page will out of work We can&amp;rsquo;t ssh to original assigned node ip We need to ssh to 192.168.0.30, 31, 32 instead Run ip a | grep bond0 get the {ip-of-bond0} Run the recover command Confirm default route by using ip r | grep default Wait for a while and access dashboard (it takes some time) Create virtual machine with name vlan1 and id: 1 Open Settings, edit http-proxy with the following values  HTTP_PROXY=http://proxy-host:port HTTPS_PROXY=http://proxy-host:port NO_PROXY=localhost,127.</description>
    </item>
    
    <item>
      <title>39-Standard user no Harvester Access</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/39-rbac-standard-user-no-access/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/39-rbac-standard-user-no-access/</guid>
      <description> As admin import/register a harvester cluster in Rancher As admin, Enable Harvester node driver As a standard user User1, login to rancher Verify User1 has no access to harvester cluster in Virtualization management page Create harvester cloud credential as User1 Verify User1 can use this cloud credential to create a node template and a node driver cluster 3 and can CRUD each resource  </description>
    </item>
    
    <item>
      <title>40-RBAC Add restricted admin User Harvester</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/40-rbac-add-restricted-admin-user-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/40-rbac-add-restricted-admin-user-harvester/</guid>
      <description> As admin import/register a harvester cluster in Rancher create restricted admin user rstradm verify rstradm has access to to Virturalization management page and the harvester cluster is listed Verify rstradm has access to Harvester UI through rancher by selecting it from the list in step 3 and can CRUD each resource  </description>
    </item>
    
    <item>
      <title>41-Import Harvester into nested Rancher</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/41-rancher-nested-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/41-rancher-nested-harvester/</guid>
      <description>Prerequisite: External network on VLAN
 Install Rancher in a VM using Docker method on Harvester cluster using the external VLAN Login rancher dashboard Navigate to Virtual Management Page Click import existing Copy the curl command  SSH to harvester master node (user: rancher) Execute the curl command to import harvester to rancher curl --insecure -sfL https://192.168.50.82/v3/import/{identifier}.yaml | kubectl apply -f - Run sudo chmod 775 /etc/rancher/rke2/rke2.yaml to solve the permission denied error Run curl command again, you should see the following successful import message namespace/cattle-system configured serviceaccount/cattle created clusterrolebinding.</description>
    </item>
    
    <item>
      <title>42-Add cloud credential KUBECONFIG</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/42-add-cloud-credential-kubeconfig/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/42-add-cloud-credential-kubeconfig/</guid>
      <description>Prerequisite: KUBECONFIG from Harvester
 Click Cluster Management Click Cloud Credentials Click createa and select Harvester Input credential name Select external cluster Input KUBECONFIG from Harvester Click Create  </description>
    </item>
    
    <item>
      <title>43-Scale up node driver RKE1</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/43-node-driver-scale-up-rke1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/43-node-driver-scale-up-rke1/</guid>
      <description>Prerequisite: RKE1 cluster in Harvester with at least 2 worker nodes
 provision a multinode cluster using harvester node driver with at least 2 worker nodes scale up a node in the cluster  </description>
    </item>
    
    <item>
      <title>44-Scale up node driver RKE2</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/44-node-driver-scale-up-rke2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/44-node-driver-scale-up-rke2/</guid>
      <description>Prerequisite: KUBECONFIG from Harvester
 provision a multinode cluster using harvester node driver with at least 2 worker nodes scale up a node in the cluster  </description>
    </item>
    
    <item>
      <title>45-Scale down node driver RKE1</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/45-node-driver-scale-down-rke1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/45-node-driver-scale-down-rke1/</guid>
      <description>Prerequisite: KUBECONFIG from Harvester
 provision a multinode cluster using harvester node driver with at least 2 worker nodes scale down a node in the cluster  </description>
    </item>
    
    <item>
      <title>46-Scale down node driver RKE2</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/46-node-driver-scale-down-rke2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/46-node-driver-scale-down-rke2/</guid>
      <description>Prerequisite: KUBECONFIG from Harvester
 provision a multinode cluster using harvester node driver with at least 2 worker nodes scale down a node in the cluster  </description>
    </item>
    
    <item>
      <title>48-Verify Backup and restore on server migration</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/48-verify-backup-restore-server-migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/48-verify-backup-restore-server-migration/</guid>
      <description> Create a harvester cluster Deploy a harvester node driver cluster preupgrade checks on both Take a backup Restore on a new rancher server from backup taken ins step 4 Run post-upgrade checks for both clusters Verify virtualization management → harvester is accessible Run p0 use case  </description>
    </item>
    
    <item>
      <title>49-Overprovision Harvester</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/49-overprovision-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/49-overprovision-harvester/</guid>
      <description> import harvester into rancher over-provision the connected harvester cluster (i.e. deploy large number of nodes) note: the number will depend on the resources available in the harvester cluster you&amp;rsquo;ve imported. i.e. a harvester setup with 24 cores, 64 GB of ram, you could try provisioning a 3cp, 2cp, 2w cluster of size 4 vCPU 8GB ram to over-provision CPU i.e. a harvester setup with 24 cores, 64 GB of ram, you could try provisioning a 3cp, 2cp, 2w cluster of size 2 vCPU 10GB ram to over-provision CPU  </description>
    </item>
    
    <item>
      <title>50-Use fleet when a harvester cluster is imported to rancher</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/50-fleet-with-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/50-fleet-with-harvester/</guid>
      <description> deploy rancher with harvester enabled docker: &amp;ndash;features=harvester=enabled helm: &amp;ndash;set &amp;lsquo;extraEnv[0].name=CATTLE_FEATURES&amp;rsquo; &amp;ndash;set &amp;lsquo;extraEnv[0].value=harvester=enabled import a harvester setup go to fleet → repos -&amp;gt; create validate that that the harvester cluster is NOT in the dropdown for cluster deployments validate that selecting the &amp;lsquo;all clusters&amp;rsquo; option for deployment does NOT deploy to the harvester cluster  </description>
    </item>
    
    <item>
      <title>51-Use harvester cloud provider to provision an LB - rke1</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/51-harvester-cloud-provider-loadbalancer-rke1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/51-harvester-cloud-provider-loadbalancer-rke1/</guid>
      <description> Provision cluster using rke1 with harvester as the node driver enable the cloud driver for harvester while provisioning the cluster run jenkins v3 validation checks once cluster comes to active  </description>
    </item>
    
    <item>
      <title>52-Use harvester cloud provider to provision an LB - rke2</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/52-harvester-cloud-provider-loadbalancer-rke2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/52-harvester-cloud-provider-loadbalancer-rke2/</guid>
      <description> Provision cluster using rke1 with harvester as the node driver enable the cloud driver for harvester while provisioning the cluster run jenkins v3 validation checks once cluster comes to active  </description>
    </item>
    
    <item>
      <title>53-Disable Harvester flag with Harvester cluster added</title>
      <link>https://harvester.github.io/tests/manual/harvester-rancher/53-disable-harvester-flag/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/harvester-rancher/53-disable-harvester-flag/</guid>
      <description>Pre-requisites: Rancher with Harvester imported
 Disable Harvester feature flag on Rancher  Expected Results  Harvester should show up in cluster management Virtualization management tab should be hidden.  </description>
    </item>
    
    <item>
      <title>Add a custom &#34;Docker Install URL&#34;</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-custom-docker-install-url/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-custom-docker-install-url/</guid>
      <description>add a harvester node template Refer to the &amp;ldquo;Test Data&amp;rdquo; value setting. Use this template to create the corresponding cluster  Expected Results  The status of the created cluster shows active the status of the corresponding vm on harvester active the information displayed on rancher and harvester matches the template configuration  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo/SATA/SCSI Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Add a custom &#34;Insecure Registries&#34;</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-custom-insecure-registries/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-custom-insecure-registries/</guid>
      <description>add a harvester node template Refer to the &amp;ldquo;Test Data&amp;rdquo; value setting. Use this template to create the corresponding cluster  Expected Results  The status of the created cluster shows active the status of the corresponding vm on harvester active the information displayed on rancher and harvester matches the template configuration Go to node, execute docker info, check the &amp;ldquo;Insecure Registries&amp;rdquo; setting is &amp;ldquo;harbor.wujing.site&amp;rdquo;  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo/SATA/SCSI Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Add a custom &#34;Registry Mirrors&#34;</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-custom-registry-mirrors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-custom-registry-mirrors/</guid>
      <description>add a harvester node template Refer to the &amp;ldquo;Test Data&amp;rdquo; value setting. Use this template to create the corresponding cluster  Expected Results  The status of the created cluster shows active the status of the corresponding vm on harvester active the information displayed on rancher and harvester matches the template configuration Go to node, execute &amp;ldquo;docker info&amp;rdquo;, check the &amp;ldquo;Registry Mirrors&amp;rdquo; setting is &amp;ldquo;https://s06nkgus.mirror.aliyuncs.com&amp;rdquo;  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo/SATA/SCSI Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Add a custom &#34;Storage Driver&#34;</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-custom-storage-driver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-custom-storage-driver/</guid>
      <description>add a harvester node template Refer to the &amp;ldquo;Test Data&amp;rdquo; value setting. Use this template to create the corresponding cluster  Expected Results  The status of the created cluster shows active the status of the corresponding vm on harvester active the information displayed on rancher and harvester matches the template configuration Go to node, execute &amp;ldquo;docker info&amp;rdquo;, check the Storage Driver setting is overlay  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo/SATA/SCSI Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Add a network to an existing VM with only 1 network</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/add-a-network-to-an-existing-vm-with-only-1-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/add-a-network-to-an-existing-vm-with-only-1-network/</guid>
      <description> Add a network to the VM Save the VM Wait for it to start/restart  Expected Results  the VM should start successfully The already existing network connectivity should still work The new connectivity should also work  </description>
    </item>
    
    <item>
      <title>Add a network to an existing VM with two networks</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/add-a-network-to-an-existing-vm-with-two-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/add-a-network-to-an-existing-vm-with-two-networks/</guid>
      <description> Add a network to the VM Save the VM Wait for it to start/restart  Expected Results  the VM should start successfully The already existing network connectivity should still work The new connectivity should also work  </description>
    </item>
    
    <item>
      <title>Add a node to existing cluster</title>
      <link>https://harvester.github.io/tests/manual/deployment/add-node-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/add-node-cluster/</guid>
      <description> Start with harvester installer and select &amp;lsquo;Join an existing Harvester cluster&amp;rsquo; Provide the management ip and cluster token  Expected Results  On completion, Harvester should show the same management url as of existing node and status as ready. Check the host section, the joined node must appear  </description>
    </item>
    
    <item>
      <title>Add cluster driver</title>
      <link>https://harvester.github.io/tests/manual/node-driver/add-cluster-driver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/add-cluster-driver/</guid>
      <description> Cluster Management &amp;gt; Drivers &amp;gt; Node Drivers Click &amp;ldquo;Add Node driver&amp;rdquo; Add the correct configuration and save  Expected Results  Created successfully, status is active  </description>
    </item>
    
    <item>
      <title>Add Labels</title>
      <link>https://harvester.github.io/tests/manual/images/add-labels/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/images/add-labels/</guid>
      <description> Add multiple labels to the images. Click save  Expected Results  Labels should be added successfully  </description>
    </item>
    
    <item>
      <title>Add multiple Networks via form</title>
      <link>https://harvester.github.io/tests/manual/network/add-multiple-networks-form/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/add-multiple-networks-form/</guid>
      <description> Create a new VM via the web form Add both a management network and an external VLAN network Validate both interfaces exist in the VM  ip link list   Ping the VM from another VM that is only on the management VLAN Ping the VM from an external machine  Expected Results  The VM should create You should see three interfaces listed in VM You should get responses from pinging the VM You should get responses from pinging the VM  </description>
    </item>
    
    <item>
      <title>Add multiple Networks via YAML</title>
      <link>https://harvester.github.io/tests/manual/network/add-multiple-networks-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/add-multiple-networks-yaml/</guid>
      <description> Create a new VM via YAML Add both a management network and an external VLAN network Validate both interfaces exist in the VM  ip link list   Ping the VM from another VM that is only on the management VLAN Ping the VM from an external machine  Expected Results  The VM should create You should see three interfaces listed in VM You should get responses from pinging the VM You should get responses from pinging the VM  </description>
    </item>
    
    <item>
      <title>Add the different roles to the cluster</title>
      <link>https://harvester.github.io/tests/manual/node-driver/q-cluster-different-roles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/q-cluster-different-roles/</guid>
      <description> Create three users user1, user2, user3 Give the roles of Cluster Owner to user1, Create Project to user2 and Cluster Member to user3 respectively. Login with these three roles  Expected Results </description>
    </item>
    
    <item>
      <title>Add VLAN network</title>
      <link>https://harvester.github.io/tests/manual/network/add-vlan-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/add-vlan-network/</guid>
      <description> Open settings on a harvester cluster Navigate to the VLAN settings page Click Enabled Add the default Physical NIC Click Save Validate that it has updated in settings  Expected Results  You should be able to add the VLAN network device You should see in the settings list that it has your new default NIC  </description>
    </item>
    
    <item>
      <title>Add/remove a node in the created harvester cluster</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-add-remove-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-add-remove-node/</guid>
      <description> add/remove a node in the created harvester cluster  Expected Results  rancher on the cluster modified successfully harvester corresponding VM node added/removed successfully  </description>
    </item>
    
    <item>
      <title>Authentication Validation</title>
      <link>https://harvester.github.io/tests/manual/authentication/general-authentication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/authentication/general-authentication/</guid>
      <description>Enable Access Control . Choose “Allow any valid User” as “Site Access”. Make sure any user is able to access the site. Enable Access Control . Choose “Restrict to Specific User” and add few users. Make sure only the specified users have access to the server. Others should get authentication error. Enable Access Control . Choose “Restrict to Specific User” and add a group. Make sure only all users belonging to the group have access to the server Others should get authentication error.</description>
    </item>
    
    <item>
      <title>Backup and restore of harvester cluster</title>
      <link>https://harvester.github.io/tests/manual/node-driver/q-cluster-backup-restore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/q-cluster-backup-restore/</guid>
      <description> create a deployment in harvester cluster Go to the rancher&amp;rsquo;s cluster list and make a backup of the harvester cluster After the backup is complete, delete the deployment created in the harvester cluster go to the list of clusters in the rancher and restore the harvester cluster  Expected Results </description>
    </item>
    
    <item>
      <title>Backup Single VM</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/backup-single-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/backup-single-vm/</guid>
      <description> Click take backup in virtual machine list  Expected Results  Backup should be created Backup should be listed in backups list Backup should be available on remote storage (S3/NFS)  </description>
    </item>
    
    <item>
      <title>Backup Single VM that has been live migrated before</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/backup-single-vm-that-has-been-live-migrated/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/backup-single-vm-that-has-been-live-migrated/</guid>
      <description> Click take backup in virtual machine list  Expected Results  Backup should be created Backup should be listed in backups list Backup should be available on remote storage (S3/NFS)  </description>
    </item>
    
    <item>
      <title>Backup single VM with node off</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/backup-single-vm-node-off/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/backup-single-vm-node-off/</guid>
      <description>On multi-node setup bring down node that is hosting VM Click take backup in virtual machine list  Expected Results  The backup should complete successfully  Comments We do allow taking backup even if the VM is down, as you can take backup when the VM is off, this is because the volume still exists with longhorn&amp;rsquo;s multi replicas, but weneed to check the data integrity.
Known Bugs https://github.</description>
    </item>
    
    <item>
      <title>Basic functional verification of Harvester cluster after creation</title>
      <link>https://harvester.github.io/tests/manual/node-driver/verify-cluster-functionality/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/verify-cluster-functionality/</guid>
      <description> create the project. deploy deployment  Expected Results  The project is created successfully Deployment successfully deployed  </description>
    </item>
    
    <item>
      <title>Change api-ui-source bundled</title>
      <link>https://harvester.github.io/tests/manual/advanced/chage-api-ui-source-bundled/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/advanced/chage-api-ui-source-bundled/</guid>
      <description> Log in as admin Navigate to advanced settings Change api-ui-source to bundled Save Refresh page Check page source for dashboard loading location  Expected Results  Log in should complete Settings should save dashboard location should be loading from /dashboard/_nuxt/  (verify it in browser&amp;rsquo;s developers tools)    </description>
    </item>
    
    <item>
      <title>Change api-ui-source external</title>
      <link>https://harvester.github.io/tests/manual/advanced/chage-api-ui-source-external/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/advanced/chage-api-ui-source-external/</guid>
      <description> Log in as admin Navigate to advanced settings Change api-ui-source to external Save Refresh page Check page source for dashboard loading location  Expected Results  Log in should complete Settings should save dashboard location should be loading from https://releases.rancher.com/harvester-ui/latest (verify it in browser&amp;rsquo;s developers tools)  </description>
    </item>
    
    <item>
      <title>Change log level debug</title>
      <link>https://harvester.github.io/tests/manual/advanced/change-log-level-debug/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/advanced/change-log-level-debug/</guid>
      <description> Log in as admin Navigate to advanced settings Edit config on log-level Choose Debug Save Create two VMs Reboot both VMs Download Logs  Expected Results  Login should complete Settings should save VMs should create VMs should reboot sucessfully Logs should show Debug level output  </description>
    </item>
    
    <item>
      <title>Change log level Info</title>
      <link>https://harvester.github.io/tests/manual/advanced/change-log-level-info/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/advanced/change-log-level-info/</guid>
      <description> Log in as admin Navigate to advanced settings Edit config on log-level Choose Info Save Create two VMs Reboot both VMs Download Logs  Expected Results  Login should complete Settings should save VMs should create VMs should reboot sucessfully Logs should show Info level output  </description>
    </item>
    
    <item>
      <title>Change log level Trace</title>
      <link>https://harvester.github.io/tests/manual/advanced/change-log-level-trace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/advanced/change-log-level-trace/</guid>
      <description> Log in as admin Navigate to advanced settings Edit config on log-level Choose Trace Save Create two VMs Reboot both VMs Download Logs  Expected Results  Login should complete Settings should save VMs should create VMs should reboot sucessfully Logs should show Trace level output  </description>
    </item>
    
    <item>
      <title>Check that you can communicate with the Harvester cluster</title>
      <link>https://harvester.github.io/tests/manual/terraformer/harvester-cluster-communicate/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraformer/harvester-cluster-communicate/</guid>
      <description>Set the KUBECONFIG env variable with the path of your kubeconfig file Try to import any resource to test the connectivity with the Harvester cluster For instance, try to import ssh-key with: terraformer import harvester -r ssh_key  Expected Results You should see:
terraformer import harvester -r ssh_key 2021/08/04 15:18:59 harvester importing... ssh_key 2021/08/04 15:18:59 harvester done importing ssh_key ... And the generated files should appear in ./generated/harvester/ssh_key/</description>
    </item>
    
    <item>
      <title>Clone VM and don&#39;t select start after creation</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-and-dont-select-start-after-creation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-and-dont-select-start-after-creation/</guid>
      <description> Clone VM from Virtual Machine list  Expected Results  Machine should start if start VM after creation was checked Machine should match the origin machine in Config In YAML You should be able to connect to new VM via console  </description>
    </item>
    
    <item>
      <title>Clone VM that is turned off</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-that-is-turned-off/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-that-is-turned-off/</guid>
      <description> Clone VM from Virtual Machine list that is turned off  Expected Results  Machine should start if start VM after creation was checked Machine should match the origin machine  in Config In YAML   You should be able to connect to new VM via console  </description>
    </item>
    
    <item>
      <title>Clone VM that is turned on</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-that-is-turned-on/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-that-is-turned-on/</guid>
      <description> Clone VM from Virtual Machine list that is turned on  Expected Results  Machine should start if start VM after creation was checked Machine should match the origin machine  in Config In YAML   You should be able to connect to new VM via console  </description>
    </item>
    
    <item>
      <title>Clone VM that was created from image</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-that-was-created-from-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-that-was-created-from-image/</guid>
      <description> Clone VM from Virtual Machine list  Expected Results  Machine should start if start VM after creation was checked Machine should match the origin machine  in Config In YAML   You should be able to connect to new VM via console  </description>
    </item>
    
    <item>
      <title>Clone VM that was created from template</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-that-was-created-from-template/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-that-was-created-from-template/</guid>
      <description> Clone VM from Virtual Machine list  Expected Results  Machine should start if start VM after creation was checked Machine should match the origin machine  in Config In YAML   You should be able to connect to new VM via console  </description>
    </item>
    
    <item>
      <title>Clone VM that was not created from image</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-that-was-not-created-from-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/clone-vm-that-was-not-created-from-image/</guid>
      <description> Clone VM from Virtual Machine list  Expected Results  Machine should start if start VM after creation was checked Machine should match the origin machine  in Config In YAML   You should be able to connect to new VM via console  </description>
    </item>
    
    <item>
      <title>Cluster add labs</title>
      <link>https://harvester.github.io/tests/manual/node-driver/create-add-labs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/create-add-labs/</guid>
      <description>add a harvester node template Refer to the &amp;ldquo;Test Data&amp;rdquo; value setting. Use this template to create the corresponding cluster  Expected Results  Use the command &amp;ldquo;kubectl get node &amp;ndash;show-labels&amp;rdquo; to see the success of the added tabs Go to the node details page of UI, click the &amp;ldquo;Edit Node&amp;rdquo; button, and check Labels  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo/SATA/SCSI Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Cluster add Taints</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-add-taints/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-add-taints/</guid>
      <description>add a harvester node template Refer to the &amp;ldquo;Test Data&amp;rdquo; value setting. Use this template to create the corresponding cluster  Expected Results  Use the command kubectl describe node test-tain5 | grep Taint to see if Taint was added successfully. Go to the node details page of UI, click the &amp;ldquo;Edit Node&amp;rdquo; button, and check Taint  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo/SATA/SCSI Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Create a 3 nodes harvester cluster with RKE1 (only with mandatory info, other values stays with default)</title>
      <link>https://harvester.github.io/tests/manual/node-driver/create-3-node-rke1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/create-3-node-rke1/</guid>
      <description> From the Rancher home page, click on Create Select RKE1 on the right and click on Harvester Enter a cluster name Give a prefix name for the VMs Increase count to 3 nodes Check etcd, Control Plane and Worker boxes Select or create a node template if needed  Click on Add node template Create credentials by selecting your harvester cluster Fill the instance option fields, pay attention to correctly write the default ssh user of the chosen image in the SSH user field Give a name to the rancher template and click on Create   Click on create to spin the cluster up  Expected Results  The status of the created cluster shows active The status of the corresponding vm on harvester active The 3 nodes should be with the active status  </description>
    </item>
    
    <item>
      <title>Create a 3 nodes harvester cluster with RKE2 (only with mandatory info, other values stays with default)</title>
      <link>https://harvester.github.io/tests/manual/node-driver/create-3-node-rke2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/create-3-node-rke2/</guid>
      <description> From the Rancher home page, click on Create Select RKE2 on the right and click on Harvester Create the credential to talk with the harvester provider  Select your harvester cluster (external or internal)   Enter a cluster name Increase machine count to 3 Fill the mandatory fields  Namespace Image Network SSH User (default ssh user of the chosen image)   Click on create to spin the cluster up  Expected Results  The status of the created cluster shows active The status of the corresponding vm on harvester active The 3 nodes should be with the active status  </description>
    </item>
    
    <item>
      <title>Create a harvester cluster and add Taint to a node</title>
      <link>https://harvester.github.io/tests/manual/node-driver/q-cluster-add-taint/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/q-cluster-add-taint/</guid>
      <description>Expected Results </description>
    </item>
    
    <item>
      <title>Create a harvester cluster with 3 master nodes</title>
      <link>https://harvester.github.io/tests/manual/node-driver/add-3-master-nodes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/add-3-master-nodes/</guid>
      <description> add a harvester node template Create harvester cluster count set to 3  Expected Results  The status of the created cluster shows active show the 3 created node status running in harvester&amp;rsquo;s vm list the information displayed on rancher and harvester matches the template configuration  </description>
    </item>
    
    <item>
      <title>Create a harvester cluster with a non-default version of k8s</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-non-default-k8s/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-non-default-k8s/</guid>
      <description> Verify versions 1.19.10, 1.18.18, 1.17.17, 1.16.15 respectively  Expected Results  k8s displayed on the UI is consistent with the created version (cluster list, host list) Use kubectl version to see that the version information is the same as the created version  </description>
    </item>
    
    <item>
      <title>Create a harvester cluster with different images</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-different-images/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-different-images/</guid>
      <description>d a harvester node template Set the image, it should be a drop-down list, refer to &amp;ldquo;Test Data&amp;rdquo; for other values  ubuntu-18.04-server-cloudimg-amd64.img focal-server-cloudimg-amd64-disk-kvm.img   Use this template to create the corresponding cluster  Expected Results  The status of the created cluster shows active The status of the corresponding vm on harvester active The information displayed on rancher and harvester matches the template configuration The drop-down list of images in the harvester node template corresponds to the list of images in the harvester  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo/SATA/SCSI Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Create a harvester cluster, template drop-down list validation</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-template-dropdown-multi-user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-template-dropdown-multi-user/</guid>
      <description> Create multiple harvester Node Templates with different users Add harvester cluster and set Template  Expected Results  pop up a template list pop-up box Show the templates you created and the templates created by other users  </description>
    </item>
    
    <item>
      <title>Create a new VM and add Enable USB tablet option</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-a-new-vm-and-add-enable-usb-tablet-option/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-a-new-vm-and-add-enable-usb-tablet-option/</guid>
      <description> Add Enable usb tablet Option Save/Create VM  Expected Results  Machine starts successfully Enable usb tablet shows  In YAML In Form    </description>
    </item>
    
    <item>
      <title>Create a new VM and add Install guest agent option</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-a-new-vm-and-add-install-guest-agent-option/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-a-new-vm-and-add-install-guest-agent-option/</guid>
      <description> Add install Guest Agent Option Save/Create VM Validate that qemu-guest-agent was installed  You can do this on ubuntu with the command dpkg -l | grep qemu    Expected Results  Machine starts successfully Guest Agent Option shows  In YAML In Form   Guest Agent is installed  </description>
    </item>
    
    <item>
      <title>Create a new VM with Network Data from the form</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-a-new-vm-with-network-data-from-the-form/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-a-new-vm-with-network-data-from-the-form/</guid>
      <description> Add Network Data to the VM  Here is an example of Network Data config to add DHCP to the physical interface eth0 network: version: 1 config: - type: physical name: eth0 subnets: - type: dhcp    Save/Create the VM  Expected Results  Machine starts succesfully Network Data should show in YAML Network Datashould show in Form Machine should have DHCP for network on eth0  </description>
    </item>
    
    <item>
      <title>Create a new VM with Network Data from YAML</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-a-new-vm-with-network-data-from-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-a-new-vm-with-network-data-from-yaml/</guid>
      <description> Add Network Data to the VM via YAML  Here is an example of Network Data config to add DHCP to the physical interface eth0 network: version: 1 config: - type: physical name: eth0 subnets: - type: dhcp    Save/Create the VM  Expected Results  Machine starts succesfully Network Data should show in YAML Network Datashould show in Form Machine should have DHCP for network on eth0  </description>
    </item>
    
    <item>
      <title>Create a new VM with User Data from the form</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-a-new-vm-with-user-data-from-the-form/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-a-new-vm-with-user-data-from-the-form/</guid>
      <description> Add User data to the VM   Here is an example of user data config to add a password #cloud-config password: password chpasswd: {expire: False} sshpwauth: True Save/Create the VM  Expected Results  Machine starts succesfully User data should exist  In YAML In Form   Machine should have user password set  </description>
    </item>
    
    <item>
      <title>Create a VM on a VLAN with an existing machine and then change the existing machine&#39;s VLAN</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-a-vm-on-a-vlan-with-an-existing-machine-and-then-change-the-existing-machines-vlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-a-vm-on-a-vlan-with-an-existing-machine-and-then-change-the-existing-machines-vlan/</guid>
      <description> Create/edit VM/VMs with the appropriate VLAN Change VLAN for VM if appropriate  Expected Results  VM should create successfully Appropriate VLAN should show  In config in YAML   VMs should NOT be able to connect on network  verify with ping/ICMP verify with SSH verify with telnet over port 80 if there&amp;rsquo;s a web server    </description>
    </item>
    
    <item>
      <title>Create a VM with 2 networks</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-a-vm-with-2-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-a-vm-with-2-networks/</guid>
      <description>Add a network to the VM Save the VM Wait for it to start/restart  Expected Results  the VM should start successfully The already existing network connectivity should still work The new connectivity should also work  Comments one default management network and one VLAN</description>
    </item>
    
    <item>
      <title>Create a vm with all the default values</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-a-vm-with-all-the-default-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-a-vm-with-all-the-default-values/</guid>
      <description> Create a VM with all default values Save  Expected Results  VM should save VM should start if start after creation checkbox is checked Config should show  In Form In YAML    </description>
    </item>
    
    <item>
      <title>Create a VM with Start VM on Creation checked</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-a-vm-with-start-vm-on-creation-checked/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-a-vm-with-start-vm-on-creation-checked/</guid>
      <description> Create VM  Expected Results  VM should start Checkbox for start virtual machine on creation should show as appropriate while editing machine after creation  </description>
    </item>
    
    <item>
      <title>Create a VM with start VM on creation unchecked</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-a-vm-with-start-vm-on-creation-unchecked/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-a-vm-with-start-vm-on-creation-unchecked/</guid>
      <description> Create VM  Expected Results  VM should start or not start as appropriate Checkbox for start virtual machine on creation should show as appropriate while editing machine after creation  </description>
    </item>
    
    <item>
      <title>Create Backup Target</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/create-backup-target/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/create-backup-target/</guid>
      <description> Open up Backup-target in settings Input server info Save  Expected Results  Backup Target should show in settings  </description>
    </item>
    
    <item>
      <title>Create harvester cluster using non-default CPUs, Memory, Disk</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-non-default-resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-non-default-resources/</guid>
      <description>add a harvester node template The set CPUs, Memory, and Disk values, refer to &amp;ldquo;Test Data&amp;rdquo; for other values Use this template to create the corresponding cluster  Expected Results  The status of the created cluster shows active the status of the corresponding vm on harvester active the information displayed on rancher and harvester matches the template configuration  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:4 Memorys:8 Disk:50 Bus:Virtlo Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Create harvester clusters with different Bus</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-different-bus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-different-bus/</guid>
      <description>add a harvester node template Set the “Network Name”, it should be a drop-down list, refer to &amp;ldquo;Test Data&amp;rdquo; for other values  VirtIO SATA SCSI   Use this template to create the corresponding cluster  Expected Results  The status of the created cluster shows active the status of the corresponding vm on harvester active the information displayed on rancher and harvester matches the template configuration The drop-down list of &amp;ldquo;BUS&amp;rdquo; in the harvester node template corresponds to the list of “BUS” in the harvester  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo/SATA/SCSI Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Create harvester clusters with different Networks</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-different-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-different-networks/</guid>
      <description>add a harvester node template Set the “Network Name”, it should be a drop-down list, refer to &amp;ldquo;Test Data&amp;rdquo; for other values  vlan1 vlan2   Use this template to create the corresponding cluster  Expected Results  The status of the created cluster shows active the status of the corresponding vm on harvester active the information displayed on rancher and harvester matches the template configuration The drop-down list of &amp;ldquo;Network Name&amp;rdquo; in the harvester node template corresponds to the list of “Network Name” in the harvester  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo/SATA/SCSI Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Create image from Volume</title>
      <link>https://harvester.github.io/tests/manual/volumes/create-image-from-volume/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/create-image-from-volume/</guid>
      <description>Create new VM Add SSH key Run through iterations for 1, 2, and 3 for attached bash script Export volume to image from volumes page Create new VM from image Run md5sum -c file2.md5 file1-2.md5 file2-2.md5 file3.md5  Expected Results  image should upload/complete in images page New VM should create SSH key should work on new VM file2.md5 should fail and the other three md5 checks should pass  Comments #!</description>
    </item>
    
    <item>
      <title>Create Images with valid image URL</title>
      <link>https://harvester.github.io/tests/manual/images/create-images-with-valid-image-url/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/images/create-images-with-valid-image-url/</guid>
      <description>Create image with cloud image available for openSUSE. http://download.opensuse.org/repositories/Cloud:/Images:/Leap_15.3/images/openSUSE-Leap-15.3.x86_64-NoCloud.qcow2  Expected Results  Image should show state as Active. Check the backing image in Longhorn  Known Bugs https://github.com/harvester/harvester/issues/1269</description>
    </item>
    
    <item>
      <title>Create multiple instances of the vm with ISO image</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-multiple-instances-vm-with-iso-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-multiple-instances-vm-with-iso-image/</guid>
      <description>Create images using the external path for ISO image. In user data mention the below to access the vm.  Create the 3 vms and wait for vm to start  Expected Results  3 vm should come up and start with same config. Observe the time taken for the system to start the vms. Observe the pattern of the vms get allocated on the nodes. Like how many vm on each nodes are created.</description>
    </item>
    
    <item>
      <title>Create multiple instances of the vm with raw image</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-multiple-instances-vm-with-raw-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-multiple-instances-vm-with-raw-image/</guid>
      <description>Create images using the external path for cloud image. In user data mention the below to access the vm.  Create the 3 vms and wait for vm to start.  Expected Results  3 vm should come up and start with same config. Observe the time taken for the system to start the vms. Observe the pattern of the vms get allocated on the nodes. Like how many vm on each nodes are created.</description>
    </item>
    
    <item>
      <title>Create multiple instances of the vm with Windows Image</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-multiple-instances-vm-with-windows-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-multiple-instances-vm-with-windows-image/</guid>
      <description>Create images using the external path for ISO image. In user data mention the below to access the vm.  Create the 3 vms and wait for vm to start.  Expected Results  3 vm should come up and start with same config. Observe the time taken for the system to start the vms. Observe the pattern of the vms get allocated on the nodes. Like how many vm on each nodes are created.</description>
    </item>
    
    <item>
      <title>Create new network</title>
      <link>https://harvester.github.io/tests/manual/network/create-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/create-network/</guid>
      <description> Navigate to the networks page in harvester Click Create Add a name Add a VLAN ID Click Create  Expected Results  You should be able to add the VLAN You should see the VLAN show up in the networks page  </description>
    </item>
    
    <item>
      <title>Create new VM with a machine type of PC</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-new-vm-with-a-machine-type-pc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-new-vm-with-a-machine-type-pc/</guid>
      <description> Set up the VM with the appropriate machine type Save/create  Expected Results  Machine should start sucessfully Machine should show the new machine type in the config and in the YAML  </description>
    </item>
    
    <item>
      <title>Create new VM with a machine type of q35</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-new-vm-with-a-machine-type-q35/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-new-vm-with-a-machine-type-q35/</guid>
      <description> Set up the VM with the appropriate machine type Save/create  Expected Results  Machine should start sucessfully Machine should show the new machine type in the config and in the YAML  </description>
    </item>
    
    <item>
      <title>Create one VM on a VLAN and then move another VM to that VLAN</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-one-vm-on-a-vlan-and-then-move-another-vm-to-that-vlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-one-vm-on-a-vlan-and-then-move-another-vm-to-that-vlan/</guid>
      <description> Create/edit VM/VMs with the appropriate VLAN  Expected Results  VM should create successfully Appropriate VLAN should show  In config in YAML   VMs should be able to connect on network  This can be verified with a ping over the IP, or via other options if ICMP is disabled    </description>
    </item>
    
    <item>
      <title>Create one VM on a VLAN that has other VMs then change it to a different VLAN</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-one-vm-on-a-vlan-that-has-other-vms-then-change-it-to-a-different-vlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-one-vm-on-a-vlan-that-has-other-vms-then-change-it-to-a-different-vlan/</guid>
      <description> Create/edit VM/VMs with the appropriate VLAN Change VLAN for VM if appropriate  Expected Results  VM should create successfully Appropriate VLAN should show  In config in YAML   VMs should NOT be able to connect on network  verify with ping/ICMP verify with SSH verify with telnet over port 80 if there&amp;rsquo;s a web server    </description>
    </item>
    
    <item>
      <title>Create Single instances of the vm with ISO image</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-single-instances-vm-with-iso-image-with-machine-type-pc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-single-instances-vm-with-iso-image-with-machine-type-pc/</guid>
      <description> Create vm using the external path for ISO image. In user data mention the below to access the vm.  #cloud-config password: password chpasswd: {expire: False} sshpwauth: True  Create the vm and wait for vm to start.  Expected Results  VM should come up and start with same config.  </description>
    </item>
    
    <item>
      <title>Create Single instances of the vm with ISO image</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-single-instances-vm-with-iso-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-single-instances-vm-with-iso-image/</guid>
      <description> Create vm using the external path for ISO image. In user data mention the below to access the vm.  #cloud-config password: password chpasswd: {expire: False} sshpwauth: True  Create the vm and wait for vm to start.  Expected Results  VM should come up and start with same config.  </description>
    </item>
    
    <item>
      <title>Create Single instances of the vm with ISO image with machine type pc</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-single-instances-vm-with-iso-image-with-machine-type-q35/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-single-instances-vm-with-iso-image-with-machine-type-q35/</guid>
      <description> Create vm using the external path for ISO image. In user data mention the below to access the vm.  #cloud-config password: password chpasswd: {expire: False} sshpwauth: True  Create the vm and wait for vm to start.  Expected Results  VM should come up and start with same config.  </description>
    </item>
    
    <item>
      <title>Create Single instances of the vm with raw image</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-single-instances-vm-with-raw-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-single-instances-vm-with-raw-image/</guid>
      <description> Create vm using the external path for cloud image. In user data mention the below to access the vm.  #cloud-config password: password chpasswd: {expire: False} sshpwauth: True  Create the vm and wait for vm to start.  Expected Results  VM should come up and start with same config.  </description>
    </item>
    
    <item>
      <title>Create Single instances of the vm with Windows Image</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-single-instances-vm-with-windows-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-single-instances-vm-with-windows-image/</guid>
      <description> Create vm using the external path for ISO image. In user data mention the below to access the vm.  #cloud-config password: password chpasswd: {expire: False} sshpwauth: True  Create the vm and wait for vm to start.  Expected Results  VM should come up and start with same config.  </description>
    </item>
    
    <item>
      <title>Create two VMs in the same VLAN</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-two-vms-in-the-same-vlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-two-vms-in-the-same-vlan/</guid>
      <description> Create/edit VM/VMs with the appropriate VLAN  Expected Results  VM should create successfully Appropriate VLAN should show  In config in YAML   VMs should be able to connect on network  This can be verified with a ping over the IP, or via other options if ICMP is disabled    </description>
    </item>
    
    <item>
      <title>Create two VMs on separate VLANs</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-two-vms-on-separate-vlans/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-two-vms-on-separate-vlans/</guid>
      <description> Create/edit VM/VMs with the appropriate VLAN Change VLAN for VM if appropriate  Expected Results  VM should create successfully Appropriate VLAN should show  In config in YAML   VMs should NOT be able to connect on network  verify with ping/ICMP verify with SSH verify with telnet over port 80 if there&amp;rsquo;s a web server    </description>
    </item>
    
    <item>
      <title>Create two VMs on the same VLAN and change one</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-two-vms-on-the-same-vlan-and-change-one/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-two-vms-on-the-same-vlan-and-change-one/</guid>
      <description> Create/edit VM/VMs with the appropriate VLAN Change VLAN for VM if appropriate  Expected Results  VM should create successfully Appropriate VLAN should show  In config in YAML   VMs should NOT be able to connect on network  verify with ping/ICMP verify with SSH verify with telnet over port 80 if there&amp;rsquo;s a web server    </description>
    </item>
    
    <item>
      <title>Create VM and add SSH key</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-and-add-ssh-key/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-and-add-ssh-key/</guid>
      <description> Create VM Add SSH key if not already in VM Logon with SSH  Expected Results  You should be prompted for SSH key passphrase if appropriate You should connect You should be able to execute shell commands The SSH Key should show in the SSH key list  </description>
    </item>
    
    <item>
      <title>Create vm using a template of default version</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-using-a-template-of-default-version/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-using-a-template-of-default-version/</guid>
      <description> Create a new VM with a template of default version  Expected Results  After selecting appropriate template and/or version it should populate other fields CPU, Memory, Image, and SSH key should match saved template info VM should start after creation if Start Virtual Machine is selected  </description>
    </item>
    
    <item>
      <title>Create vm using a template of default version with machine type pc</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-using-a-template-of-default-version-with-machine-type-pc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-using-a-template-of-default-version-with-machine-type-pc/</guid>
      <description> Create a new VM with a template of default version  Expected Results  After selecting appropriate template and/or version it should populate other fields CPU, Memory, Image, and SSH key should match saved template info VM should start after creation if Start Virtual Machine is selected  </description>
    </item>
    
    <item>
      <title>Create vm using a template of default version with machine type q35</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-using-a-template-of-default-version-with-machine-type-q35/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-using-a-template-of-default-version-with-machine-type-q35/</guid>
      <description> Create a new VM with a template of default version  Expected Results  After selecting appropriate template and/or version it should populate other fields CPU, Memory, Image, and SSH key should match saved template info VM should start after creation if Start Virtual Machine is selected  </description>
    </item>
    
    <item>
      <title>Create vm using a template of non-default version</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-using-a-template-non-default-version/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-using-a-template-non-default-version/</guid>
      <description> Create a new VM with a template of non-default version  Expected Results  After selecting appropriate template and/or version it should populate other fields CPU, Memory, Image, and SSH key should match saved template info VM should start after creation if Start Virtual Machine is selected  </description>
    </item>
    
    <item>
      <title>Create vm with both CPU and Memory not in cluster</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-both-cpu-and-memory-not-in-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-both-cpu-and-memory-not-in-cluster/</guid>
      <description> Attempt to create a VM with the appropriate resources  Expected Results  You should get errors for each resource you over provisioned The VM should not create until errors are resolved  </description>
    </item>
    
    <item>
      <title>Create vm with CPU not in cluster.</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-cpu-not-in-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-cpu-not-in-cluster/</guid>
      <description> Attempt to create a VM with the appropriate resources  Expected Results  You should get errors for each resource you over provisioned The VM should not create until errors are resolved  </description>
    </item>
    
    <item>
      <title>Create VM with existing Volume</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-existing-volume/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-existing-volume/</guid>
      <description> Create VM with an existing volume  Expected Results  VM should create and start You should be able to open the console for the VM and see it boot Volume should show in volumes list VM should appear to the &amp;ldquo;Attached VM&amp;rdquo; column of the existing volume  </description>
    </item>
    
    <item>
      <title>Create vm with Memory not in cluster.</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-memory-not-in-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-memory-not-in-cluster/</guid>
      <description> Attempt to create a VM with the appropriate resources  Expected Results  You should get errors for each resource you over provisioned The VM should not create until errors are resolved  </description>
    </item>
    
    <item>
      <title>Create VM with resources that are only on one node in cluster CPU</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-resources-that-are-only-on-one-node-in-cluster-cpu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-resources-that-are-only-on-one-node-in-cluster-cpu/</guid>
      <description> Create a VM with resources that are only available on one node in cluster  Expected Results  VM should create VM should be assigned to node that has available resources VM should boot VM should pass health checks  </description>
    </item>
    
    <item>
      <title>Create VM with resources that are only on one node in cluster CPU</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-with-resources-that-are-only-on-one-node-in-cluster-cpu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-with-resources-that-are-only-on-one-node-in-cluster-cpu/</guid>
      <description> Edit a VM with resources that are only available on one node in cluster.  Expected Results  VM should save VM should be reassigned to node that has available resources VM should boot VM should pass health checks  </description>
    </item>
    
    <item>
      <title>Create VM with resources that are only on one node in cluster CPU and Memory</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-resources-that-are-only-on-one-node-in-cluster-cpu-and-memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-resources-that-are-only-on-one-node-in-cluster-cpu-and-memory/</guid>
      <description> Create a VM with resources that are only available on one node in cluster  Expected Results  VM should create VM should be assigned to node that has available resources VM should boot VM should pass health checks  </description>
    </item>
    
    <item>
      <title>Create VM with resources that are only on one node in cluster Memory</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-resources-that-are-only-on-one-node-in-cluster-memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-resources-that-are-only-on-one-node-in-cluster-memory/</guid>
      <description> Create a VM with resources that are only available on one node in cluster  Expected Results  VM should create VM should be assigned to node that has available resources VM should boot VM should pass health checks  </description>
    </item>
    
    <item>
      <title>Create VM with resources that are only on one node in cluster Memory</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-with-resources-that-are-only-on-one-node-in-cluster-memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-with-resources-that-are-only-on-one-node-in-cluster-memory/</guid>
      <description> Edit a VM with resources that are only available on one node in cluster.  Expected Results  VM should save VM should be reassigned to node that has available resources VM should boot VM should pass health checks  </description>
    </item>
    
    <item>
      <title>Create VM with saved SSH key</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-saved-ssh-key/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-saved-ssh-key/</guid>
      <description> Create VM Add SSH key if not already in VM Logon with SSH  Expected Results  You should be prompted for SSH key passphrase if appropriate You should connect You should be able to execute shell commands The SSH Key should show in the SSH key list  </description>
    </item>
    
    <item>
      <title>Create VM with the default network</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-the-default-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-the-default-network/</guid>
      <description> Create a VM with the default network Let VM boot up after creation  Expected Results  VM should start VM should be able to ping other machines in the VLAN VM should be able to ping servers on the internet if the VLAN has external access  </description>
    </item>
    
    <item>
      <title>Create VM with two disk volumes</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-two-disk-volumes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-vm-with-two-disk-volumes/</guid>
      <description> Create a VM with the appropriate number of volumes  Expected Results  Verify after creation that the appropriate volumes are in the config for the VM Verify that the volumes are created and listed in the volumes section  </description>
    </item>
    
    <item>
      <title>Create Volume root disk blank Form with label</title>
      <link>https://harvester.github.io/tests/manual/volumes/create-volume-root-disk-blank-form-label/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/create-volume-root-disk-blank-form-label/</guid>
      <description> Navigate to volumes page Click Create Don&amp;rsquo;t select an image Input a size Click Create  Expected Results  Page should load Volume should create successfully and go to succeeded in the list The label can be seen when you edit the volume config  </description>
    </item>
    
    <item>
      <title>Create volume root disk VM Image Form</title>
      <link>https://harvester.github.io/tests/manual/volumes/create-volume-root-disk-vm-image-form/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/create-volume-root-disk-vm-image-form/</guid>
      <description> Navigate to volumes page Click Create Select an image Input a size Click Create  Expected Results  VM should create VM should pass health checks  </description>
    </item>
    
    <item>
      <title>Create volume root disk VM Image Form with label</title>
      <link>https://harvester.github.io/tests/manual/volumes/create-volume-root-disk-vm-image-form-label/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/create-volume-root-disk-vm-image-form-label/</guid>
      <description> Navigate to volumes page Click Create Select an image Input a size Click Create  Expected Results  Page should load Volume should create successfully and go to succeeded in the list The label can be seen when you edit the volume config  </description>
    </item>
    
    <item>
      <title>Create Windows VM</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/create-windows-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/create-windows-vm/</guid>
      <description>Create a VM with the VM template with windows-iso-image-base-temp Config the CPU and Memory to 4 and 8 respectively Select the windows ISO image Click the Volumes tab and update the root disk size to 50GB Click create to launch the windows VM Optional: you can increase the second disk size or add an additional one. Click create to launch the VM (this will take a couple of minutes upon your network speed of download the ISO image) Click the Console to launch a VNC console of the windows server, and you will need to find an evaluation key of the windows server 2012 installation.</description>
    </item>
    
    <item>
      <title>Create with invalid image</title>
      <link>https://harvester.github.io/tests/manual/images/negative-create-with-invalid-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/images/negative-create-with-invalid-image/</guid>
      <description> Create image with invalid URL. e.g. - https://test.img  Expected Results  Image state show as Failed  </description>
    </item>
    
    <item>
      <title>datavolumes.cdi.kubevirt.io</title>
      <link>https://harvester.github.io/tests/manual/webhooks/datavolumes.cdi.kubevirt.io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/webhooks/datavolumes.cdi.kubevirt.io/</guid>
      <description>GUI  Create a VM in GUI and wait until it&amp;rsquo;s running. Assume its name is test.  kube-api  Try to delete its datavolume:  $ kubectl get vms NAME AGE STATUS READY test 5m16s Running True  There should be an datavolume bound to that VM  $ kubectl get dvs NAME PHASE PROGRESS RESTARTS AGE test-disk-0-klrft Succeeded 100.0% 5m18s  The user should not be able to delete the datavolume  $ kubectl delete dv test-disk-0-klrft The request is invalid: : can not delete the volume test-disk-0-klrft which is currently attached to VMs: default/test `` ## Expected Results ### kube-api The deletion of its datavolume should fail.</description>
    </item>
    
    <item>
      <title>Deactivate/activate/delete Harvester Node Driver</title>
      <link>https://harvester.github.io/tests/manual/node-driver/deactivate-activate-deletenode-driver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/deactivate-activate-deletenode-driver/</guid>
      <description>With Rancher &amp;lt; 2.6:
 Tools-&amp;gt;Driver Management→Node Driver Deactivate/activate/delete Harvester Node Driver With Rancher 2.6: Cluster Management &amp;gt; Drivers &amp;gt; Node Drivers Deactivate/activate/delete Harvester Node Driver  Expected Results  Harvester icon is not visible when creating a cluster / Harvester icon is visible when creating a cluster /Harvester icon is not visible when creating a cluster  </description>
    </item>
    
    <item>
      <title>Delete backup from backups list</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/delete-single-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/delete-single-backup/</guid>
      <description> Delete backup from backups list  Expected Results  Backup should be removed from list Backup should be removed from remote storage  </description>
    </item>
    
    <item>
      <title>Delete Cluster</title>
      <link>https://harvester.github.io/tests/manual/node-driver/cluster-delete/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/cluster-delete/</guid>
      <description> Delete Cluster  Expected Results  successful cluster deletion in rancher the corresponding VM node in harvester is deleted successfully  </description>
    </item>
    
    <item>
      <title>Delete external VLAN network via form</title>
      <link>https://harvester.github.io/tests/manual/network/delete-vlan-network-form/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/delete-vlan-network-form/</guid>
      <description> On a VM with both an external VLAN and a management VLAN delete the external VLAN via the web form Validate interface was removed with  ip link list   Ping the VM from another VM that is only on the management VLAN Ping the VM from an external machine  Expected Results  The VM should update and reboot You should only see one interface (and the loopback) in the list You should not be able to ping the VM on the external VLAN You should get responses from the VM  </description>
    </item>
    
    <item>
      <title>Delete external VLAN network via YAML</title>
      <link>https://harvester.github.io/tests/manual/network/delete-vlan-network-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/delete-vlan-network-yaml/</guid>
      <description> On a VM with both an external VLAN and a management VLAN delete the external VLAN via YAML Validate interface was removed with  ip link list   Ping the VM from another VM that is only on the management VLAN Ping the VM from an external machine  Expected Results  The VM should update and reboot You should only see one interface (and the loopback) in the list You should not be able to ping the VM on the external VLAN You should get responses from the VM  </description>
    </item>
    
    <item>
      <title>Delete first backup in chained backup</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/delete-first-backup-chained-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/delete-first-backup-chained-backup/</guid>
      <description> Create a new VM Create a file named 1 and add text Create a backup Edit text in file 1 create file 2 Create Backup Edit file 2 text Create file 3 and add text Create backup Delete backup 1 Validate file 2 and 3 are the same as they were Restore to backup 2 Validate that  md5sum -c file1-2.md5 file2.md5 file3.md5 file 1 is in second format file 2 is in first format file 3 doesn&amp;rsquo;t exist    Expected Results  Vm should create All file operations should create Backup should run All file operations should create Backup should run All file operations should create files should be as expected  </description>
    </item>
    
    <item>
      <title>Delete Host</title>
      <link>https://harvester.github.io/tests/manual/hosts/delete-host/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/delete-host/</guid>
      <description> Navigate to the Hosts page and select the node Click Delete  Expected Results  SSH to the node and check the nodes has components deleted.  </description>
    </item>
    
    <item>
      <title>Delete host that has VMs on it</title>
      <link>https://harvester.github.io/tests/manual/hosts/delete-host-with-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/delete-host-with-vm/</guid>
      <description>Navigate to the Hosts page and select the node Click Delete  Expected Results  An alert message should appear. If VM exists it should stop user to delete the node or move VM to other node. If VM is getting moved to another node and there is no space, it should stop user to delete the node.  Existing bugs https://github.com/harvester/harvester/issues/1004</description>
    </item>
    
    <item>
      <title>Delete last backup in chained backup</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/delete-last-backup-chained-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/delete-last-backup-chained-backup/</guid>
      <description>Create a new VM Create a file named 1 and add some data using command dd if=/dev/urandom of=file1.txt count=100 bs=1M Compute md5sum : md5sum-1 Create a backup Overwrite file 1 Create file 2 Compute md5sum for file 1 and file 2 : md5sum-2, md5sum-3 Create Backup Overwrite the file 2 Create file 3 and compute md5sum for file 2 and file 3 : md5sum-4, md5sum-5 Create backup delete backup 3 Validate that files didn&amp;rsquo;t change Restore to backup 2 Validate that  md5sum -c file1-2.</description>
    </item>
    
    <item>
      <title>Delete management network via form</title>
      <link>https://harvester.github.io/tests/manual/network/delete-management-network-form/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/delete-management-network-form/</guid>
      <description> On a VM with both an external VLAN and a management VLAN delete the management VLAN via the web form Validate interface was removed with  ip link list   Ping the VM from another VM that is only on the management VLAN Ping the VM from an external machine  Expected Results  The VM should update and reboot You should only see one interface (and the loopback) in the list You should not be able to ping the VM on the management VLAN You should get responses from the VM  </description>
    </item>
    
    <item>
      <title>Delete management network via YAML</title>
      <link>https://harvester.github.io/tests/manual/network/delete-management-network-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/delete-management-network-yaml/</guid>
      <description> On a VM with both an external VLAN and a management VLAN delete the management network via YAML Validate interface was removed with  ip link list   Ping the VM from another VM that is only on the management VLAN Ping the VM from an external machine  Expected Results  The VM should update and reboot You should only see one interface (and the loopback) in the list You should not be able to ping the VM on the management network You should get responses from the VM  </description>
    </item>
    
    <item>
      <title>Delete middle backup in chained backup</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/delete-middle-backup-chained-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/delete-middle-backup-chained-backup/</guid>
      <description>Create a new VM Create a file named 1 and add some data using command dd if=/dev/urandom of=file1.txt count=100 bs=1M Compute md5sum : md5sum-1 Create a backup Overwrite file 1 Create file 2 Compute md5sum for file 1 and file 2 : md5sum-2, md5sum-3 Create Backup Overwrite the file 2 Create file 3 and compute md5sum for file 2 and file 3 : md5sum-4, md5sum-5 Create backup Delete backup 2 Validate file 2 and 3 are the same as they were Restore to backup 1 Validate that  md5sum -c file1.</description>
    </item>
    
    <item>
      <title>Delete multiple backups</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/delete-multiple-backups/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/delete-multiple-backups/</guid>
      <description> Select multiple Backups from Backups list Click Delete  Expected Results  Backups should be removed from list Backups should be removed from remote storage  </description>
    </item>
    
    <item>
      <title>Delete multiple VMs with disks</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/delete-multiple-vms-with-disks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/delete-multiple-vms-with-disks/</guid>
      <description> Delete VM Select whether you want to delete disks  Expected Results  You should check amount of used space on Server before you delete the VM Machine should delete It should not show up in the Virtual Machine list Disks should be listed/or not in Volumes list as appropriate Verify the cleaned up the space on the disk on the node.  </description>
    </item>
    
    <item>
      <title>Delete multiple VMs without disks</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/delete-multiple-vms-without-disks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/delete-multiple-vms-without-disks/</guid>
      <description> Delete VM Select whether you want to delete disks  Expected Results  You should check amount of used space on Server before you delete the VM Machine should delete It should not show up in the Virtual Machine list Disks should be listed/or not in Volumes list as appropriate Verify the cleaned up the space on the disk on the node.  </description>
    </item>
    
    <item>
      <title>Delete single vm all disks</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/delete-single-vm-all-disks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/delete-single-vm-all-disks/</guid>
      <description> Delete VM Select whether you want to delete disks  Expected Results  You should check amount of used space on Server before you delete the VM Machine should delete It should not show up in the Virtual Machine list Disks should be listed/or not in Volumes list as appropriate Verify the cleaned up the space on the disk on the node.  </description>
    </item>
    
    <item>
      <title>Delete the image</title>
      <link>https://harvester.github.io/tests/manual/images/delete-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/images/delete-image/</guid>
      <description> Select an image with state active. Delete the image. Create another image with same name. Delete the newly created image. Delete an image with failed state  Expected Results  The image should be deleted successfully. Check the CRDS VirtualMachineImage. User should be able to create a new image with same name. Check the backing image in Longhorn.  </description>
    </item>
    
    <item>
      <title>Delete VM Negative</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/negative-delete-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/negative-delete-vm/</guid>
      <description> In a multi-node setup disconnect/shutdown the node where the VM is running Delete VM and all disks  Expected Results  You should not be able to delete the VM  </description>
    </item>
    
    <item>
      <title>Delete volume that is not attached to a VM</title>
      <link>https://harvester.github.io/tests/manual/volumes/delete-volume-that-is-not-attached-to-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/delete-volume-that-is-not-attached-to-vm/</guid>
      <description> Create volume Validate that it created Check the volume crd. Delete the volume Verify that volume is removed from list Check the volume object doesn&amp;rsquo;t exist anymore.  Expected Results  Volume should create It should show in volume list Volume crd should have correct info. Volume should delete. Volume should be removed from list  </description>
    </item>
    
    <item>
      <title>Delete volume that was attached to VM but now is not</title>
      <link>https://harvester.github.io/tests/manual/volumes/delete-volume-that-was-attached-to-vm-but-is-not-now/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/delete-volume-that-was-attached-to-vm-but-is-not-now/</guid>
      <description> Create a VM with a root volume Write 10Gi data into it. Delete the VM but not the volume Verify Volume still exists Check disk space on node Delete the volume Verify that volume is removed from list Check disk space on node  Expected Results  VM should create 10Gi space should be consumed on the disk. VM should delete Volume should still show in Volume list Disk space should show 10Gi + Volume should delete Volume should be removed from list Space should be less than before  </description>
    </item>
    
    <item>
      <title>Download host YAML</title>
      <link>https://harvester.github.io/tests/manual/hosts/download-host-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/download-host-yaml/</guid>
      <description> Navigate to the Hosts page and select the node Click Download Yaml  Expected Results  The Yaml should get downloaded.  </description>
    </item>
    
    <item>
      <title>Edit a VM and add install Enable usb tablet option</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-and-add-install-enable-usb-tablet-option/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-and-add-install-enable-usb-tablet-option/</guid>
      <description> Add Enable usb tablet Option Save/Create VM  Expected Results  Machine starts successfully Enable usb tablet shows  In YAML In Form    </description>
    </item>
    
    <item>
      <title>Edit a VM and add install guest agent option</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-and-add-install-guest-agent-option/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-and-add-install-guest-agent-option/</guid>
      <description> Add install Guest Agent Option Save/Create VM  Expected Results  Machine starts successfully Guest Agent Option shows  In YAML In Form   Guest Agent is installed  </description>
    </item>
    
    <item>
      <title>Edit a VM from the form to add Network Data</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-from-the-form-to-add-network-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-from-the-form-to-add-network-data/</guid>
      <description> Add Network Data to the VM  Here is an example of Network Data config to add DHCP to the physical interface eth0  network: version: 1 config: - type: physical name: eth0 subnets: - type: dhcp  Save/Create the VM  Expected Results  Machine starts succesfully Network Data should show in YAML Network Datashould show in Form Machine should have DHCP for network on eth0  </description>
    </item>
    
    <item>
      <title>Edit a VM from the form to add user data</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-from-the-form-to-add-user-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-from-the-form-to-add-user-data/</guid>
      <description> Add User data to the VM  Here is an example of user data config to add a password `` #cloud-config password: password chpasswd: {expire: False} sshpwauth: True   Save/Create the VM  Expected Results  Machine starts succesfully User data should  In YAML In Form   Machine should have user password set  </description>
    </item>
    
    <item>
      <title>Edit a VM from the YAML to add Network Data</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-from-the-yaml-to-add-network-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-from-the-yaml-to-add-network-data/</guid>
      <description> Add Network Data to the VM  Here is an example of Network Data config to add DHCP to the physical interface eth0  network: version: 1 config: - type: physical name: eth0 subnets: - type: dhcp  Save/Create the VM  Expected Results  Machine starts succesfully Network Data should show in YAML Network Datashould show in Form Machine should have DHCP for network on eth0  </description>
    </item>
    
    <item>
      <title>Edit a VM from the YAML to add user data</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-from-the-yaml-to-add-user-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-from-the-yaml-to-add-user-data/</guid>
      <description> Add User data to the VM  Here is an example of user data config to add a password `` #cloud-config password: password chpasswd: {expire: False} sshpwauth: True   Save/Create the VM  Expected Results  Machine starts succesfully User data should  In YAML In Form   Machine should have user password set  </description>
    </item>
    
    <item>
      <title>Edit an existing VM to another machine type</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-an-existing-vm-to-another-machine-type/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-an-existing-vm-to-another-machine-type/</guid>
      <description> Set up the VM with the appropriate machine type Save/create  Expected Results  Machine should start sucessfully Machine should show the new machine type in the config and in the YAML  </description>
    </item>
    
    <item>
      <title>Edit backup read YAML from file</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/edit-backup-read-yaml-from-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/edit-backup-read-yaml-from-file/</guid>
      <description> Edit YAML for backup Read from File Show Diff Save  Expected Results  Diff should show changes Backup should be updated  </description>
    </item>
    
    <item>
      <title>Edit backup via YAML</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/edit-backup-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/edit-backup-yaml/</guid>
      <description> Edit YAML for backup Show Diff Save  Expected Results  Diff should show changes Backup should be updated  </description>
    </item>
    
    <item>
      <title>Edit Config</title>
      <link>https://harvester.github.io/tests/manual/hosts/edit-config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/edit-config/</guid>
      <description> Navigate to the Hosts page and select the node Click edit config. Add description and other details Try to modify the network config  Expected Results  The edited values should be saved and reflected on the page.  </description>
    </item>
    
    <item>
      <title>Edit Config YAML</title>
      <link>https://harvester.github.io/tests/manual/hosts/edit-config-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/edit-config-yaml/</guid>
      <description> Navigate to the Hosts page and select the node Click edit config through YAML. Add description and other details Try to modify the network config  Expected Results  The edited values should be saved and reflected on the page.  </description>
    </item>
    
    <item>
      <title>Edit images</title>
      <link>https://harvester.github.io/tests/manual/images/edit-images/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/images/edit-images/</guid>
      <description> Edit image.  Try to edit the description Try to edit the URL Try to edit the Labels    Expected Results  User should be able to edit the description and Labels User should not be able to edit the URL  </description>
    </item>
    
    <item>
      <title>Edit network via form change external VLAN to management network</title>
      <link>https://harvester.github.io/tests/manual/network/edit-network-form-change-vlan-to-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/edit-network-form-change-vlan-to-management/</guid>
      <description> Edit VM and change external VLAN to management network with bridge type via the web form Ping VM Attempt to SSH to VM  Expected Results  VM should save and reboot You should be able to ping the VM from an external network You should be able to SSH to VM  </description>
    </item>
    
    <item>
      <title>Edit network via form change management network to external VLAN</title>
      <link>https://harvester.github.io/tests/manual/network/edit-network-form-change-management-to-vlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/edit-network-form-change-management-to-vlan/</guid>
      <description> Edit VM and change management network to external VLAN with bridge type via the web form Ping VM Attempt to SSH to VM  Expected Results  VM should save and reboot You should be able to ping the VM from an external network You should be able to SSH to VM  </description>
    </item>
    
    <item>
      <title>Edit network via YAML change external VLAN to management network</title>
      <link>https://harvester.github.io/tests/manual/network/edit-network-yaml-change-vlan-to-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/edit-network-yaml-change-vlan-to-management/</guid>
      <description> Edit VM and change external VLAN to management network with bridge type via YAML Ping VM Attempt to SSH to VM  Expected Results  VM should save and reboot You should be able to ping the VM from an external network You should be able to SSH to VM  </description>
    </item>
    
    <item>
      <title>Edit network via YAML change management network to external VLAN</title>
      <link>https://harvester.github.io/tests/manual/network/edit-network-yaml-change-management-to-vlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/edit-network-yaml-change-management-to-vlan/</guid>
      <description> Edit VM and change management network to external VLAN with bridge type via YAML Ping VM Attempt to SSH to VM  Expected Results  VM should save and reboot You should be able to ping the VM from an external network You should be able to SSH to VM  </description>
    </item>
    
    <item>
      <title>Edit vm and insert ssh and check the ssh key is accepted for the login</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-and-insert-ssh-and-check-the-ssh-key-is-accepted-for-the-login/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-and-insert-ssh-and-check-the-ssh-key-is-accepted-for-the-login/</guid>
      <description> Edit VM and add SSH Key Save VM  Expected Results  You should be able to ssh in with correct SSH private key You should not be able to SSH in with incorrect SSH private key  </description>
    </item>
    
    <item>
      <title>Edit VM Form Negative</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/negative-edit-vm-form/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/negative-edit-vm-form/</guid>
      <description> In a multi-node setup disconnect/shutdown the node where the VM is running Edit the VM via form Save the VM  Expected Results  You should not be able to save the edited Form You should get an error  </description>
    </item>
    
    <item>
      <title>Edit vm network and verify the network is working as per configuration</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-network-and-verify-the-network-is-working-as-per-configuration-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-network-and-verify-the-network-is-working-as-per-configuration-/</guid>
      <description> Edit VM network Save  Expected Results  VM should save VM should restart if restart checkbox is checked Changes should show  In Form In YAML   Network should function as desired  </description>
    </item>
    
    <item>
      <title>Edit VM via form with CPU</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-form-with-cpu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-form-with-cpu/</guid>
      <description> Edit VM Save  Expected Results  VM should save VM should restart if restart checkbox is checked Changes should show  In Form In YAML    </description>
    </item>
    
    <item>
      <title>Edit VM via form with CPU and Memory</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-form-with-cpu-and-memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-form-with-cpu-and-memory/</guid>
      <description> Edit VM Save  Expected Results  VM should save VM should restart if restart checkbox is checked Changes should show  In Form In YAML    </description>
    </item>
    
    <item>
      <title>Edit VM via form with Memory</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-form-with-memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-form-with-memory/</guid>
      <description> Edit VM Save  Expected Results  VM should save VM should restart if restart checkbox is checked Changes should show  In Form In YAML    </description>
    </item>
    
    <item>
      <title>Edit VM via YAML with CPU</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-yaml-with-cpu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-yaml-with-cpu/</guid>
      <description> Edit VM Save  Expected Results  VM should save VM should restart if restart checkbox is checked Changes should show  In Form In YAML    </description>
    </item>
    
    <item>
      <title>Edit VM via YAML with CPU and Memory</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-yaml-with-cpu-and-memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-yaml-with-cpu-and-memory/</guid>
      <description> Edit VM Save  Expected Results  VM should save VM should restart if restart checkbox is checked Changes should show  In Form In YAML    </description>
    </item>
    
    <item>
      <title>Edit VM via YAML with Memory</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-yaml-with-memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-vm-via-yaml-with-memory/</guid>
      <description> Edit VM Save  Expected Results  VM should save VM should restart if restart checkbox is checked Changes should show  In Form In YAML    </description>
    </item>
    
    <item>
      <title>Edit VM with resources that are only on one node in cluster CPU and Memory</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-with-resources-that-are-only-on-one-node-in-cluster-cpu-and-memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/edit-a-vm-with-resources-that-are-only-on-one-node-in-cluster-cpu-and-memory/</guid>
      <description> Edit a VM with resources that are only available on one node in cluster.  Expected Results  VM should save VM should be reassigned to node that has available resources VM should boot VM should pass health checks  </description>
    </item>
    
    <item>
      <title>Edit VM YAML Negative</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/q-negative-edit-vm-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/q-negative-edit-vm-yaml/</guid>
      <description> In a multi-node setup disconnect/shutdown the node where the VM is running Edit the VM via YAML Save the VM  Expected Results  SSH to the node and check the nodes has components deleted.  </description>
    </item>
    
    <item>
      <title>Edit volume decrease size via YAML</title>
      <link>https://harvester.github.io/tests/manual/volumes/edit-volume-decrase-size-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/edit-volume-decrase-size-yaml/</guid>
      <description> Stop the vm Navigate to volumes page Edit Volume as YAML Decrease size Click Save Connect to VM via console Check size of root disk  Expected Results  VM should stop VM should reboot after saving Disk should be resized  </description>
    </item>
    
    <item>
      <title>Edit volume decrease size via YAML</title>
      <link>https://harvester.github.io/tests/manual/volumes/edit-volume-decrease-size-form/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/edit-volume-decrease-size-form/</guid>
      <description> Stop the vm Navigate to volumes page Edit Volume as YAML Decrease size Click Save Connect to VM via console Check size of root disk  Expected Results  VM should stop VM should reboot after saving Disk should be resized  </description>
    </item>
    
    <item>
      <title>Edit Volume Form add label</title>
      <link>https://harvester.github.io/tests/manual/volumes/edit-volume-form-add-label/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/edit-volume-form-add-label/</guid>
      <description> Navigate to volumes page Edit Volume with Form Click Labels Add label Click Save Open VM again and click the config tab Verify that label was saved  Expected Results  Volume should save Label should add Label should show when re-opened  </description>
    </item>
    
    <item>
      <title>Edit volume increase size via form</title>
      <link>https://harvester.github.io/tests/manual/volumes/edit-volume-increase-size-form/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/edit-volume-increase-size-form/</guid>
      <description> Stop the vm Navigate to volumes page Edit Volume via form Increase size Click Save Connect to VM via console Check size of root disk  Expected Results  VM should stop VM should reboot after saving Disk should be resized  </description>
    </item>
    
    <item>
      <title>Edit volume increase size via YAML</title>
      <link>https://harvester.github.io/tests/manual/volumes/edit-volume-increase-size-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/edit-volume-increase-size-yaml/</guid>
      <description> Stop the vm Navigate to volumes page Edit Volume as YAML Increase size Click Save Connect to VM via console Check size of root disk  Expected Results  VM should stop VM should reboot after saving Disk should be resized  </description>
    </item>
    
    <item>
      <title>Edit Volume YAML add label</title>
      <link>https://harvester.github.io/tests/manual/volumes/edit-volume-yaml-add-label/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/edit-volume-yaml-add-label/</guid>
      <description> Navigate to volumes page Edit Volume as YAML Add label to config Click Save Open VM again and click the config tab Verify that label was saved  Expected Results  Volume should save Label should add Label should show when re-opened  </description>
    </item>
    
    <item>
      <title>Filter backups</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/filter-backups/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/filter-backups/</guid>
      <description> Enter in string in filter input field  Columns available for matching:  State  &amp;ldquo;Ready&amp;rdquo; &amp;ldquo;Progressing&amp;rdquo;   Name Target VM   With string  With matching string  Input Clear   With non-matching string  Input Clear Clear String        Expected Results  List should filter based on string List should re-populate after clearing string  </description>
    </item>
    
    <item>
      <title>First Time Login</title>
      <link>https://harvester.github.io/tests/manual/authentication/first-time-login/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/authentication/first-time-login/</guid>
      <description> After successful installation of Harvester using Iso, on navigating to UI, user should be prompted to change the password. Verify the password rules  Expected Results  User should be able to login  </description>
    </item>
    
    <item>
      <title>Guest CSI Driver</title>
      <link>https://harvester.github.io/tests/manual/node-driver/guest-csi-driver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/guest-csi-driver/</guid>
      <description>Start rancher using docker in a vm and start harvester in another Import harvester into rancher from &amp;ldquo;Virtualization Management&amp;rdquo; page On rancher, enable harvester node driver at &amp;ldquo;Cluster Management&amp;rdquo; -&amp;gt; &amp;ldquo;Drivers&amp;rdquo; -&amp;gt; &amp;ldquo;Node Driver&amp;rdquo; Go back to &amp;ldquo;Cluster Management&amp;rdquo; and create a rke2 cluster using Harvester Once the created cluster is active on the &amp;ldquo;Cluster Management&amp;rdquo; page, click on the &amp;ldquo;Explore&amp;rdquo; Go to &amp;ldquo;Workload&amp;rdquo; -&amp;gt; &amp;ldquo;Deployment&amp;rdquo; and &amp;ldquo;Create&amp;rdquo; a new deployment, during which in the page of &amp;ldquo;Storage&amp;rdquo;, click on &amp;ldquo;Add Volume&amp;rdquo; and select &amp;ldquo;Create Persistent Volume Claim&amp;rdquo; and select &amp;ldquo;Harvester&amp;rdquo; in the &amp;ldquo;Storage Class&amp;rdquo; Click &amp;ldquo;Create&amp;rdquo; to create the deployment Verify that on the Harvester side, a new volume is created.</description>
    </item>
    
    <item>
      <title>Import and make changes to clusternetwork resource</title>
      <link>https://harvester.github.io/tests/manual/terraformer/import-edit-clusternetwork/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraformer/import-edit-clusternetwork/</guid>
      <description>Import clusternetwork resource  terraformer import harvester -r clusternetwork  Replace the provider (already explained in the installation process above) terraform plan and apply command should print &amp;ldquo;No changes.&amp;rdquo; Alter the resource and check with terraform plan then terraform apply For instance, alter the following properties: default_physical_nic, enable in the clusternetwork.tf file Check the change through either the UI or the API  Expected Results  Import output  terraformer import harvester -r clusternetwork 2021/08/04 15:43:25 harvester importing.</description>
    </item>
    
    <item>
      <title>Import and make changes to image resource</title>
      <link>https://harvester.github.io/tests/manual/terraformer/import-edit-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraformer/import-edit-image/</guid>
      <description>Import image resource terraformer import harvester -r image Replace the provider (already explained in the installation process above) terraform plan and apply command should print &amp;ldquo;No changes.&amp;rdquo; Alter the resource and check with terraform plan then terraform apply For instance, alter the following properties: description, display_name, name, namespace and url in the image.tf file Check the change through either the UI or the API  Expected Results  Import output  terraformer import harvester -r image 2021/08/04 16:14:52 harvester importing.</description>
    </item>
    
    <item>
      <title>Import and make changes to network resource</title>
      <link>https://harvester.github.io/tests/manual/terraformer/import-edit-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraformer/import-edit-network/</guid>
      <description>Import network resource terraformer import harvester -r network Replace the provider (already explained in the installation process above) terraform plan and apply command should print &amp;ldquo;No changes.&amp;rdquo; Alter the resource and check with terraform plan then terraform apply For instance, alter the following properties: name, namespace and vlan_id in the network.tf file Check the change through either the UI or the API  Expected Results  Import output  terraformer import harvester -r network 2021/08/04 16:14:08 harvester importing.</description>
    </item>
    
    <item>
      <title>Import and make changes to ssh_key resource</title>
      <link>https://harvester.github.io/tests/manual/terraformer/import-edit-ssh-key/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraformer/import-edit-ssh-key/</guid>
      <description>Import ssh_key resource terraformer import harvester -r ssh_key Replace the provider (already explained in the installation process above) terraform plan and apply command should print &amp;ldquo;No changes.&amp;rdquo; Alter the resource and check with terraform plan then terraform apply For instance, alter the following properties: name, namespace and public_key in the ssh_key.tf file Check the change through either the UI or the API  Expected Results  Import output  terraformer import harvester -r ssh_key 2021/08/04 16:14:36 harvester importing.</description>
    </item>
    
    <item>
      <title>Import and make changes to virtual machine resource</title>
      <link>https://harvester.github.io/tests/manual/terraformer/import-edit-virtual-machine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraformer/import-edit-virtual-machine/</guid>
      <description>Import virtual machine resource terraformer import harvester -r virtualmachine Replace the provider (already explained in the installation process above) terraform plan and apply command should print &amp;ldquo;No changes.&amp;rdquo; Alter the resource and check with terraform plan then terraform apply For instance, alter the following properties: cpu, memory, name in the virtualmachine.tf file Check the change through either the UI or the API  Expected Results  Import output  terraformer import harvester -r virtualmachine 2021/08/04 16:15:08 harvester importing.</description>
    </item>
    
    <item>
      <title>Import and make changes to volume resource</title>
      <link>https://harvester.github.io/tests/manual/terraformer/import-edit-volume/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraformer/import-edit-volume/</guid>
      <description>Import volume resource terraformer import harvester -r volume Replace the provider (already explained in the installation process above) terraform plan and apply command should print &amp;ldquo;No changes.&amp;rdquo; Alter the resource and check with terraform plan then terraform apply For instance, alter the following properties: name, namespace in the volume.tf file Check the change through either the UI or the API  Expected Results  Import output  terraformer import harvester -r volume 2021/08/04 16:15:29 harvester importing.</description>
    </item>
    
    <item>
      <title>Import External Harvester</title>
      <link>https://harvester.github.io/tests/manual/node-driver/import-external-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/import-external-harvester/</guid>
      <description>With Rancher &amp;lt; 2.6:
 Deploy the rancher and harvester clusters separately In the rancher, add a harvester node template Select &amp;ldquo;External Harvester&amp;rdquo;, and refer to &amp;ldquo;Test Data&amp;rdquo; for other value settings. Use this template to create the corresponding cluster With Rancher 2.6: Home page / Import Existing / Generic Add cluster name and click on Create Follow the registration steps  Expected Results  The status of the created cluster shows active The status of the corresponding vm on harvester active The information displayed on rancher and harvester matches the template configuration  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access External Harvester Host: Port: 443 Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Import internal harvester</title>
      <link>https://harvester.github.io/tests/manual/node-driver/import-internal-harvester/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/import-internal-harvester/</guid>
      <description>enable harvester&amp;rsquo;s rancher-enabled setting Click the rancher button in the upper right corner to access the internal rancher add a harvester node template Select &amp;ldquo;Internal Harvester&amp;rdquo;, and refer to &amp;ldquo;Test Data&amp;rdquo; for other value settings. Use this template to create the corresponding cluster  Expected Results  The status of the created cluster shows active the status of the corresponding vm on harvester active the information displayed on rancher and harvester matches the template configuration  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Initiate multiple migrations at one time</title>
      <link>https://harvester.github.io/tests/manual/live-migration/initiate-multple-migrations-same-time/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/initiate-multple-migrations-same-time/</guid>
      <description> Initiate live migration for a vm. While the live migration is in progress, initiate another migration  Expected Results  Both migration should work fine. The VMs should be accessible after the migration  </description>
    </item>
    
    <item>
      <title>Install Harvester on a bare Metal node using ISO image</title>
      <link>https://harvester.github.io/tests/manual/deployment/install-bare-metal-iso/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/install-bare-metal-iso/</guid>
      <description>Install using ISO image https://docs.harvesterhci.io/v0.3/install/iso-install/
Expected Results  On completion of the installation, Harvester should provide the management url and show status. Harvester and Longhorn components should be up and running in the cluster. Verify the memory, cpu and storage size shown on the Harvester UI  </description>
    </item>
    
    <item>
      <title>Install Harvester on a bare Metal node using ISO image</title>
      <link>https://harvester.github.io/tests/manual/deployment/install-nested-virtualization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/install-nested-virtualization/</guid>
      <description>Install using ISO image https://docs.harvesterhci.io/v0.3/install/iso-install/
Expected Results  On completion of the installation, Harvester should provide the management url and show status. Harvester and Longhorn components should be up and running in the cluster. Verify the memory, cpu and storage size shown on the Harvester UI  </description>
    </item>
    
    <item>
      <title>Install Harvester on a bare Metal node using PXE boot</title>
      <link>https://harvester.github.io/tests/manual/deployment/install-bare-metal-pxe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/install-bare-metal-pxe/</guid>
      <description>Install Harvester using PXE boot https://docs.harvesterhci.io/v0.3/install/pxe-boot-install/
Expected Results  On completion of the installation, Harvester should provide the management url and show status. Harvester and Longhorn components should be up and running in the cluster. Verify the memory, cpu and storage size shown on the Harvester UI  </description>
    </item>
    
    <item>
      <title>Installation of the Harvester terraform provider</title>
      <link>https://harvester.github.io/tests/manual/terraform-provider/install-terraform-provider/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraform-provider/install-terraform-provider/</guid>
      <description>Follow the instruction of the README
Expected Results The provider is initialized and the terraform init command succeeds:
Initializing provider plugins... - Finding harvester/harvester versions matching &amp;quot;~&amp;gt; 0.1.0&amp;quot;... - Installing harvester/harvester v0.1.0... - Installed harvester/harvester v0.1.0 (unauthenticated) ... Terraform has been successfully initialized! </description>
    </item>
    
    <item>
      <title>keypairs.harvesterhci.io</title>
      <link>https://harvester.github.io/tests/manual/webhooks/keypairs.harvesterhci.io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/webhooks/keypairs.harvesterhci.io/</guid>
      <description>GUI  Enable VLAN network in settings Create a network with VLAN 5 and assume its name is my-network. C1. reate another network with VLAN 5: it should fails with: admission webhook &amp;ldquo;validator.harvesterhci.io&amp;rdquo; denied the request: VLAN ID 5 is already allocated Create a VM on VLAN 5, delete network my-network and it should fail with: admission webhook &amp;ldquo;validator.harvesterhci.io&amp;rdquo; denied the request: network my-network is still used by vm(s): vm-test in a modal.</description>
    </item>
    
    <item>
      <title>Login after password reset</title>
      <link>https://harvester.github.io/tests/manual/authentication/login-after-password-reset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/authentication/login-after-password-reset/</guid>
      <description> Enter the wrong credential. Enter the correct credential  Expected Results  Login should fail. Login should pass  </description>
    </item>
    
    <item>
      <title>Logout from the UI and login again</title>
      <link>https://harvester.github.io/tests/manual/authentication/logout-then-login/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/authentication/logout-then-login/</guid>
      <description> Logout from the UI and Log in again  Expected Results  User should be able to logout/login successfully.  </description>
    </item>
    
    <item>
      <title>Maintenance mode for host with multiple VMs</title>
      <link>https://harvester.github.io/tests/manual/hosts/maintenance-mode-multiple-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/maintenance-mode-multiple-vm/</guid>
      <description> Put host in maintenance mode Migrate VMs Wait for VMs to migrate Wait for any vms to migrate off Do health check on VMs  Expected Results  Host should start to go into maintenance mode Any VMs should migrate off Host should go into maintenance mode  </description>
    </item>
    
    <item>
      <title>Maintenance mode for host with one VM</title>
      <link>https://harvester.github.io/tests/manual/hosts/maintenance-mode-one-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/maintenance-mode-one-vm/</guid>
      <description> Put host in maintenance mode Migrate VMs Wait for VMs to migrate Wait for any vms to migrate off Do health check on VMs  Expected Results  Host should start to go into maintenance mode Any VMs should migrate off Host should go into maintenance mode  </description>
    </item>
    
    <item>
      <title>Maintenance mode on node with no vms</title>
      <link>https://harvester.github.io/tests/manual/hosts/maintenance-mode-no-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/maintenance-mode-no-vm/</guid>
      <description> Put host in maintenance mode Wait for host to go from entering maintenance mode to maintenance mode.  Expected Results  Host should start to go into maintenance mode Host should go into maintenance mode  </description>
    </item>
    
    <item>
      <title>Migrate a turned on VM from one host to another</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-turned-on-vm-to-another-host/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-turned-on-vm-to-another-host/</guid>
      <description> Create a new file on the machine Migrate the VM from one host in the cluster to another Connect via console Check for the file Change the file and save it Verify that you can close and open the file again  Expected Results  File should create correctly VM should go into migrating status VM should go out of migrating status It should show the new node on the host column in the VM list It should have the same IP You should be able to edit and re-open the file  </description>
    </item>
    
    <item>
      <title>Migrate a VM created with cloud init config data</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-vm-with-cloud-init/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-vm-with-cloud-init/</guid>
      <description> Create a new VM with cloud init config data Create a new file on the machine Migrate the VM from one host in the cluster to another Connect via console Check for the file Change the file and save it Verify that you can close and open the file again  Expected Results  File should create correctly VM should go into migrating status VM should go out of migrating status It should show the new node on the host column in the VM list It should have the same IP You should be able to edit and re-open the file  </description>
    </item>
    
    <item>
      <title>Migrate a VM created with user data config</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-vm-with-user-data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-vm-with-user-data/</guid>
      <description> Create a new VM with a password specified by user data config Create a new file on the machine Migrate the VM from one host in the cluster to another Connect via console Check for the file Change the file and save it Verify that you can close and open the file again  Expected Results  File should create correctly VM should go into migrating status VM should go out of migrating status It should show the new node on the host column in the VM list It should have the same IP You should be able to edit and re-open the file  </description>
    </item>
    
    <item>
      <title>Migrate a VM that has multiple volumes</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-vm-multiple-volumes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-vm-multiple-volumes/</guid>
      <description> Create a new VM with a root disk and a CDROM volume Create a new file on the machine Migrate the VM from one host in the cluster to another Connect via console Check for the file Change the file and save it Verify that you can close and open the file again  Expected Results  File should create correctly VM should go into migrating status VM should go out of migrating status It should show the new node on the host column in the VM list It should have the same IP You should be able to edit and re-open the file  </description>
    </item>
    
    <item>
      <title>Migrate a VM that was created from a template</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-vm-created-from-template/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-vm-created-from-template/</guid>
      <description> Create a new VM from a template Create a new file on the machine Migrate the VM from one host in the cluster to another Connect via console Check for the file Change the file and save it Verify that you can close and open the file again  Expected Results  File should create correctly VM should go into migrating status VM should go out of migrating status It should show the new node on the host column in the VM list It should have the same IP You should be able to edit and re-open the file  </description>
    </item>
    
    <item>
      <title>Migrate a VM that was created using a restore backup to new VM</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-vm-created-from-restore-to-new/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-vm-created-from-restore-to-new/</guid>
      <description> Take an existing backup Restore the backup to a new VM Create a new file on the machine Migrate the VM from one host in the cluster to another Connect via console Check for the file Change the file and save it Verify that you can close and open the file again  Expected Results  File should create correctly VM should go into migrating status VM should go out of migrating status It should show the new node on the host column in the VM list It should have the same IP You should be able to edit and re-open the file  </description>
    </item>
    
    <item>
      <title>Migrate a VM with 1 backup</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-vm-with-one-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-vm-with-one-backup/</guid>
      <description> Create a new VM Create a backup Add a new file to the home directory Create a new file on the machine Migrate the VM from one host in the cluster to another Connect via console Check for the file Change the file and save it Verify that you can close and open the file again  Expected Results  File should create correctly VM should go into migrating status VM should go out of migrating status It should show the new node on the host column in the VM list It should have the same IP You should be able to edit and re-open the file  </description>
    </item>
    
    <item>
      <title>Migrate a VM with a saved SSH Key</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-vm-with-ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-vm-with-ssh/</guid>
      <description> Create a new VM with an SSH key Create a new file on the machine Migrate the VM from one host in the cluster to another Connect via console Check for the file Change the file and save it Verify that you can close and open the file again  Expected Results  File should create correctly VM should go into migrating status VM should go out of migrating status It should show the new node on the host column in the VM list It should have the same IP You should be able to edit and re-open the file  </description>
    </item>
    
    <item>
      <title>Migrate a VM with multiple backups</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-vm-multiple-backups/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-vm-multiple-backups/</guid>
      <description> Create a new VM Create a backup Add a new file to the home directory Create a new backup Create a new file on the machine Migrate the VM from one host in the cluster to another Connect via console Check for the file Change the file and save it Verify that you can close and open the file again  Expected Results  File should create correctly VM should go into migrating status VM should go out of migrating status It should show the new node on the host column in the VM list It should have the same IP You should be able to edit and re-open the file  </description>
    </item>
    
    <item>
      <title>Migrate a VM with multiple networks</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-vm-multiple-networks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-vm-multiple-networks/</guid>
      <description> Create a new VM with  one management network in masquerade mode one VLAN network   Create a new file on the machine Migrate the VM from one host in the cluster to another Connect via console Check for the file Change the file and save it Verify that you can close and open the file again  Expected Results  File should create correctly VM should go into migrating status VM should go out of migrating status It should show the new node on the host column in the VM list It should have the same IP You should be able to edit and re-open the file  </description>
    </item>
    
    <item>
      <title>Migrate back VMs that were on host after taking host out of maintenance mode</title>
      <link>https://harvester.github.io/tests/manual/hosts/q-maintenance-mode-migrate-back-vms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/q-maintenance-mode-migrate-back-vms/</guid>
      <description>Migrate all VMs back to host that were migrated off  Expected Results I&amp;rsquo;m not sure about the expected behavior on this. I&amp;rsquo;m checking.</description>
    </item>
    
    <item>
      <title>Migrate to Node without replicaset</title>
      <link>https://harvester.github.io/tests/manual/live-migration/migrate-to-node-without-replicaset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/migrate-to-node-without-replicaset/</guid>
      <description> Create a new VM on a 4 node cluster Check which nodes have copies of the replica set Migrate the VM to the host that does not have the volume  Expected Results  VM should create correctly  </description>
    </item>
    
    <item>
      <title>Multi-browser login</title>
      <link>https://harvester.github.io/tests/manual/authentication/multi-browser-login/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/authentication/multi-browser-login/</guid>
      <description> Login via Chrome, firefox, edge, safari etc  Expected Results  Chrome, firefox, edge, safari etc should have same behavior.  </description>
    </item>
    
    <item>
      <title>Negative create backup on store that is full (NFS)</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-backup-full-backup-target/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-backup-full-backup-target/</guid>
      <description> Initiate a backup with existing VM where the NFS store is full  Expected Results  You should get an error  </description>
    </item>
    
    <item>
      <title>Negative Create Backup Target</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-create-backup-target/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-create-backup-target/</guid>
      <description> Open up Backup-target in settings Input Incorrect server info Save  Expected Results  You should get an error on saving  </description>
    </item>
    
    <item>
      <title>Negative delete backup while restore is in progress</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-delete-backup-while-restoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-delete-backup-while-restoring/</guid>
      <description> Create a backup of VM which has data more than 10Gi. Add 2Gi data in the same VM. Initiate deletion of the backup. While deletion is in progress, create another backup  Expected Results  Creation of backup should be prevented as there is a deletion is in progress. Once the deletion is completed, the backup creation should take place  </description>
    </item>
    
    <item>
      <title>Negative delete multiple backups</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-delete-multiple-backups/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-delete-multiple-backups/</guid>
      <description> Disconnect Backup Target Select multiple Backups from Backups list Click Delete  Expected Results  You should get an error  </description>
    </item>
    
    <item>
      <title>Negative delete single backup</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-delete-single-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-delete-single-backup/</guid>
      <description> Take down backup target either by account, or via network blocking Delete backup from backups list  Expected Results  You should get an error  </description>
    </item>
    
    <item>
      <title>Negative delete Volume that is in use</title>
      <link>https://harvester.github.io/tests/manual/volumes/negative-delete-volume-that-is-in-use/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/negative-delete-volume-that-is-in-use/</guid>
      <description> Navigate to Volumes page and check for a volume in use by a VM Try to delete volume Click delete on modal  Expected Results  Page should load You should get an error message on the delete modal  </description>
    </item>
    
    <item>
      <title>Negative disrupt backup server while restore is in progress</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-disrupt-backup-target-while-restoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-disrupt-backup-target-while-restoring/</guid>
      <description> Initiate a backup restore from NFS server. Disconnect network from NFS server for 5 secs Verify the restore status  Expected Results  The restore is not be interrupted and should complete. Data should be intact  </description>
    </item>
    
    <item>
      <title>Negative edit backup read from file YAML</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-edit-backup-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-edit-backup-file/</guid>
      <description> Disconnect backup target Edit YAML for backup Read from File Show Diff Save  Expected Results  You should get an error on saving  </description>
    </item>
    
    <item>
      <title>Negative edit backup YAML</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-edit-backup-yaml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-edit-backup-yaml/</guid>
      <description> Disconnect backup target Edit YAML for backup Show Diff Save  Expected Results  You should get an error on saving  </description>
    </item>
    
    <item>
      <title>Negative initiate a backup while system is taking another backup</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-backup-while-taking-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-backup-while-taking-backup/</guid>
      <description> Start a VM backup, bk-1 of a VM which has data d1 While the backup is in progress, write some more data d2 in the VM disk and initiate another backup bk-2. Verify the backup 1 and backup 2  Expected Results  Backup bk-1 should have only d1 data backup bk-2 should have data d1 and d2  </description>
    </item>
    
    <item>
      <title>Negative migrate a turned on VM from one host to another</title>
      <link>https://harvester.github.io/tests/manual/live-migration/negative-migrate-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/negative-migrate-vm/</guid>
      <description> Migrate the VM from one host in the cluster to another Turn off/disconnect node while migrating  Expected Results  Migration should fail You should get an error message in the status  </description>
    </item>
    
    <item>
      <title>Negative network comes back up after reboot external VLAN</title>
      <link>https://harvester.github.io/tests/manual/network/negative-vlan-after-reboot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/negative-vlan-after-reboot/</guid>
      <description> Start pinging the VM reboot the VM  Expected Results  The VM should respond The VM should reboot The pings should stop getting responses The pings should start getting responses again  </description>
    </item>
    
    <item>
      <title>Negative network comes back up after reboot management network</title>
      <link>https://harvester.github.io/tests/manual/network/negative-management-after-reboot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/negative-management-after-reboot/</guid>
      <description> Start pinging the VM from the management network reboot the VM  Expected Results  The VM should respond The VM should reboot The pings should stop getting responses The pings should start getting responses again  </description>
    </item>
    
    <item>
      <title>Negative network disconnection for a longer time while migration is in progress</title>
      <link>https://harvester.github.io/tests/manual/live-migration/negative-network-disconnect-while-migrating/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/negative-network-disconnect-while-migrating/</guid>
      <description> Initiate VM migration While migration is in progress, disconnect network for 100 sec on the node where the VM is scheduled  Expected Results  Migration should fail but volume data should be intact The VM should be accessible during the migration and should also be accessible once the migration fails  </description>
    </item>
    
    <item>
      <title>Negative network disconnection for a short time while migration is in progress</title>
      <link>https://harvester.github.io/tests/manual/live-migration/negative-network-disruption-while-migrating/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/negative-network-disruption-while-migrating/</guid>
      <description> Initiate VM migration. While migration is in progress, disconnect network for 5 sec on the node where the VM is scheduled  Expected Results  Migration should resume once the network is up again The VM should be accessible during and after the migration  </description>
    </item>
    
    <item>
      <title>Negative node down while migration is in progress</title>
      <link>https://harvester.github.io/tests/manual/live-migration/negative-node-down-while-migrating/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/negative-node-down-while-migrating/</guid>
      <description> Initiate VM migration. While migration is in progress, shut the node where the VM is scheduled. After failure, initiate the migration to another node  Expected Results  Migration should fail but volume data should be intact The VM should be accessible on older node The migration scheduled for another node should work fine The VM should be accessible during and after the migration  </description>
    </item>
    
    <item>
      <title>Negative node un-schedulable during live migration</title>
      <link>https://harvester.github.io/tests/manual/live-migration/negative-node-unschedulable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/negative-node-unschedulable/</guid>
      <description>Prerequisite:  Cluster is of 3 nodes. VM is running on Node-1 Node-2 and Node-3 don&amp;rsquo;t have space to migrate a VM to them.  Steps:  Create a vm on node-1 Migrate the VM.  Expected Results  Migration should not be started. Relevant error should be shown on the GUI. The existing VM should be accessible and the health check of the VM should be fine  </description>
    </item>
    
    <item>
      <title>Negative Power down the node where the VM is getting replaced by the restore</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-power-down-node-while-restoring-replace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-power-down-node-while-restoring-replace/</guid>
      <description> Initiate a restore with existing VM. While the restore is in progress and VM is starting on a node, shut down the node  Expected Results  You should get an error  </description>
    </item>
    
    <item>
      <title>Negative power down the node where the VM is getting restored</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-power-down-node-while-restoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-power-down-node-while-restoring/</guid>
      <description> Initiate a restore. While the restore is in progress and VM is starting on a node, shut down the node  Expected Results  The restore should fail  </description>
    </item>
    
    <item>
      <title>Negative restore backup replace existing VM</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-restore-backup-replace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-restore-backup-replace/</guid>
      <description> On multi-node setup bring down node that is hosting VM Navigate to backups list Click restore Backup Select appropriate option Select backup Click restore  Expected Results  You should get an error on restoring  </description>
    </item>
    
    <item>
      <title>Negative restore backup replace existing VM with backup from same VM that is turned on</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-restore-backup-replace-while-deleting-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-restore-backup-replace-while-deleting-backup/</guid>
      <description> Make sure VM is turned on Navigate to backups list Click restore Backup Select appropriate option Select backup Click restore Delete backup while restoring  Expected Results  You should get an error  </description>
    </item>
    
    <item>
      <title>Negative restore backup replace existing VM with backup from same VM that is turned on</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/negative-restore-backup-replace-while-turned-on/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/negative-restore-backup-replace-while-turned-on/</guid>
      <description> Make sure VM is turned on Navigate to backups list Click restore Backup Select appropriate option Select backup Click restore  Expected Results  You get an error that you have to stop VM before restoring backup  </description>
    </item>
    
    <item>
      <title>network-attachment-definitions.k8s.cni.cncf.io</title>
      <link>https://harvester.github.io/tests/manual/webhooks/q-network-attachment-definitions.k8s.cni.cncf.io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/webhooks/q-network-attachment-definitions.k8s.cni.cncf.io/</guid>
      <description>GUI  Enable VLAN network in settings Create a network with VLAN 5 and assume its name is my-network. Create another network with VLAN 5: it should fails with: admission webhook &amp;ldquo;validator.harvesterhci.io&amp;rdquo; denied the request: VLAN ID 5 is already allocated Create a VM on VLAN 5, delete network my-network and it should fail with: admission webhook &amp;ldquo;validator.harvesterhci.io&amp;rdquo; denied the request: network my-network is still used by vm(s): vm-test in a modal  Expected Results GUI Unsure of desired behavior.</description>
    </item>
    
    <item>
      <title>Power down a node out of three nodes available for the Cluster</title>
      <link>https://harvester.github.io/tests/manual/deployment/negative-power-off-one-node-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/negative-power-off-one-node-cluster/</guid>
      <description> Create a three nodes cluster for Harvester. Power down an added node.  Expected Results  On power down the node, the status of the node should become down. Harvester system system should be still up.  </description>
    </item>
    
    <item>
      <title>Power down and power up the node</title>
      <link>https://harvester.github.io/tests/manual/hosts/negative-power-down-power-up-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/negative-power-down-power-up-node/</guid>
      <description>Create two vms on a cluster. Power down the node. Try to migrate a VM from the down node to active node. Leave the 2nd vm as it is. Power on the node  Expected Results  The 1st VM should be migrated to other node on manually doing it. The 2nd VM should be accessible once the node is up.  Known bugs https://github.com/harvester/harvester/issues/982</description>
    </item>
    
    <item>
      <title>Power down the management node.</title>
      <link>https://harvester.github.io/tests/manual/deployment/negative-power-down-management-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/negative-power-down-management-node/</guid>
      <description> Create a three nodes cluster for Harvester. Power down the first node which was added to the cluster.  Expected Results  On power down the node, the status of the node should become down. Harvester system system should be still up.  </description>
    </item>
    
    <item>
      <title>Power down the node</title>
      <link>https://harvester.github.io/tests/manual/hosts/negative-power-down-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/negative-power-down-node/</guid>
      <description> Create two vms on a cluster. Power down the node. Try to migrate a VM from the down node to active node. Leave the 2nd vm as it is.  Expected Results  The 1st VM should be migrated to other node on manually doing it. The 2nd VM should be recovered from the lost node  </description>
    </item>
    
    <item>
      <title>Reboot host that is in maintenance mode</title>
      <link>https://harvester.github.io/tests/manual/hosts/maintenance-mode-reboot-host/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/maintenance-mode-reboot-host/</guid>
      <description>For Host that is in maintenance mode and turned on Reboot host  Expected Results  Host should reboot Maintenance mode label in hosts list should go from yellow to red to yellow  Known Bugs https://github.com/harvester/harvester/issues/1272</description>
    </item>
    
    <item>
      <title>Reboot node</title>
      <link>https://harvester.github.io/tests/manual/hosts/negative-reboot-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/negative-reboot-node/</guid>
      <description> Create a vm on the cluster. Reboot the node where the vm exists. Reboot the node where there is no vm  Expected Results  On rebooting the node, once the node is back up and Harvester is started, the host should become available on the cluster.  </description>
    </item>
    
    <item>
      <title>Reboot the management node/added node.</title>
      <link>https://harvester.github.io/tests/manual/deployment/negative-reboot-management-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/negative-reboot-management-node/</guid>
      <description> Create a three nodes cluster for Harvester. Reboot the management node/added node.  Expected Results  Once the node is up after reboot, the node should become available in the cluster.  </description>
    </item>
    
    <item>
      <title>Remove a management node from a 3 nodes cluster and add it back to the cluster by reinstalling it</title>
      <link>https://harvester.github.io/tests/manual/hosts/remove-management-node-then-reinstall/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/remove-management-node-then-reinstall/</guid>
      <description> From a HA cluster with 3 nodes Delete one of the nodes after the node promotion(all 3 nodes are management nodes) Reinstall the removed node with the same node name and IP The rejoined node will be promoted to master automatically  Expected Results  The removed node should be able to rejoin the cluster without issues  Comments  Purpose is to cover this scenario: https://github.com/harvester/harvester/issues/1040 Check the job promotion with the command kubectl get jobs -n harvester-system If a node is stuck in the removing status, you likely face to this issue, execute this command as workaround: kubectl get node -o name &amp;lt;nodename&amp;gt; | xargs -i kubectl patch {} -p &#39;{&amp;quot;metadata&amp;quot;:{&amp;quot;finalizers&amp;quot;:[]}}&#39; --type=merge  </description>
    </item>
    
    <item>
      <title>Remove a node from the existing cluster</title>
      <link>https://harvester.github.io/tests/manual/deployment/remove-node-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/remove-node-cluster/</guid>
      <description>Remove node from the Harvester cluster using the Harvester UI  Expected Results The components of Harvester should get cleaned up from the node.</description>
    </item>
    
    <item>
      <title>Remove unavailable node with VMs on it</title>
      <link>https://harvester.github.io/tests/manual/hosts/negative-remove-unavailable-node-with-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/negative-remove-unavailable-node-with-vm/</guid>
      <description>Create VMs on a host. Turn off Host Remove Host from hosts list  Expected Results  VMs should migrate to new host  Known Bugs https://github.com/harvester/harvester/issues/983</description>
    </item>
    
    <item>
      <title>Restore backup create new vm</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/restore-backup-create-new-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/restore-backup-create-new-vm/</guid>
      <description> Create a new file before restoring the backup and add some data Stop the VM where the backup was taken Navigate to backups list Click restore Backup Select appropriate option Select backup Click restore Validate that new file is no longer present on machine  Expected Results  Backup should restore VM should update to previous backup File should no longer be present  </description>
    </item>
    
    <item>
      <title>Restore Backup for VM that was live migrated</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/restore-backup-for-vm-live-migrated/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/restore-backup-for-vm-live-migrated/</guid>
      <description> Navigate to backups list Click restore Backup Select appropriate option Select backup Click restore Validate that new file is no longer present on machine  Expected Results  Backup should restore VM should update to previous backup File should no longer be present  </description>
    </item>
    
    <item>
      <title>Restore backup replace existing VM with backup from same VM</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/restore-backup-replace-existing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/restore-backup-replace-existing/</guid>
      <description> Create a new file before restoring the backup and add some data Stop the VM Navigate to backups list Click restore Backup Select appropriate option Select backup Click restore Validate that new file is no longer present on machine  Expected Results  Backup should restore VM should update to previous backup File should no longer be present  </description>
    </item>
    
    <item>
      <title>Restore First backup in chained backup</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/restore-first-backup-chained-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/restore-first-backup-chained-backup/</guid>
      <description>Create a new VM Create a file named 1 and add some data using command dd if=/dev/urandom of=file1.txt count=100 bs=1M Compute md5sum : md5sum-1 Create a backup Overwrite file 1 Create file 2 Compute md5sum for file 1 and file 2 : md5sum-2, md5sum-3 Create Backup Overwrite the file 2 Create file 3 and compute md5sum for file 2 and file 3 : md5sum-4, md5sum-5 Create backup Validate that files didn&amp;rsquo;t change Restore to backup 1 Validate that  md5sum -c file1.</description>
    </item>
    
    <item>
      <title>Restore last backup in chained backup</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/restore-last-backup-chained-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/restore-last-backup-chained-backup/</guid>
      <description>Create a new VM Create a file named 1 and add some data using command dd if=/dev/urandom of=file1.txt count=100 bs=1M Compute md5sum : md5sum-1 Create a backup Overwrite file 1 Create file 2 Compute md5sum for file 1 and file 2 : md5sum-2, md5sum-3 Create Backup Overwrite the file 2 Create file 3 and compute md5sum for file 2 and file 3 : md5sum-4, md5sum-5 Create backup Validate that files didn&amp;rsquo;t change Restore to backup 3 Validate that  md5sum -c file1-2.</description>
    </item>
    
    <item>
      <title>Restore middle backup in chained backup</title>
      <link>https://harvester.github.io/tests/manual/backup-and-restore/restore-middle-backup-chained-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/backup-and-restore/restore-middle-backup-chained-backup/</guid>
      <description>Create a new VM Create a file named 1 and add some data using command dd if=/dev/urandom of=file1.txt count=100 bs=1M Compute md5sum : md5sum-1 Create a backup Overwrite file 1 Create file 2 Compute md5sum for file 1 and file 2 : md5sum-2, md5sum-3 Create Backup Overwrite the file 2 Create file 3 and compute md5sum for file 2 and file 3 : md5sum-4, md5sum-5 Create backup Validate that files didn&amp;rsquo;t change Restore to backup 2 Validate that  md5sum -c file1-2.</description>
    </item>
    
    <item>
      <title>Run multiple instances of the console</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/run-multiple-instances-console/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/run-multiple-instances-console/</guid>
      <description> Open up the console on two browsers to simulate multiple connections Login with both browsers create a new file on both instances Edit the file from the other instance and save Verify that you can see the changes from the other instance  Expected Results  You should be able to login from multiple browsers File should create File should update You should be able to see changes from all instances  </description>
    </item>
    
    <item>
      <title>Set backup target S3</title>
      <link>https://harvester.github.io/tests/manual/advanced/set-s3-backup-target/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/advanced/set-s3-backup-target/</guid>
      <description> Log in as admin Navigate to advanced settings Edit config on backup-target Choose S3 Set valid S3 target Save  Expected Results  login should complete Settings should save You should not get an error message  </description>
    </item>
    
    <item>
      <title>Set backup-target NFS</title>
      <link>https://harvester.github.io/tests/manual/advanced/set-nfs-backup-target/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/advanced/set-nfs-backup-target/</guid>
      <description> Log in as admin Navigate to advanced settings Edit config on backup-target Choose NFS Set valid NFS target Save  Expected Results  login should complete Settings should save You should not get an error message  </description>
    </item>
    
    <item>
      <title>Set backup-target NFS invalid target</title>
      <link>https://harvester.github.io/tests/manual/advanced/negative-set-invalid-nfs-backup-target/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/advanced/negative-set-invalid-nfs-backup-target/</guid>
      <description> Log in as admin Navigate to advanced settings Edit config on backup-target Choose NFS Set invalid NFS target Save  Expected Results  login should complete Settings should save You should get an error message  </description>
    </item>
    
    <item>
      <title>Set backup-target S3 invalid target</title>
      <link>https://harvester.github.io/tests/manual/advanced/negative-set-invalid-s3-backup-target/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/advanced/negative-set-invalid-s3-backup-target/</guid>
      <description> Log in as admin Navigate to advanced settings Edit config on backup-target Choose S3 Set invalid S3 target Save  Expected Results  login should complete Settings should save You should get an error message  </description>
    </item>
    
    <item>
      <title>Start Host in maintenance mode</title>
      <link>https://harvester.github.io/tests/manual/hosts/maintenance-mode-start-host/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/maintenance-mode-start-host/</guid>
      <description>For Host that is in maintenance mode and turned off Start host  Expected Results  Host should turn on Maintenance mode label in hosts list should go from red to yellow  Known bugs https://github.com/harvester/harvester/issues/1272</description>
    </item>
    
    <item>
      <title>Start VM and stop node Negative</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/negative-start-vm-and-stop-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/negative-start-vm-and-stop-node/</guid>
      <description> Start the VM In a multi-node setup disconnect/shutdown the node where the VM is running  Expected Results  You should not be able to start the VM  </description>
    </item>
    
    <item>
      <title>Start VM Negative</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/negative-start-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/negative-start-vm/</guid>
      <description> In a multi-node setup disconnect/shutdown the node where the VM is running Start the VM  Expected Results  You should not be able to start the VM  </description>
    </item>
    
    <item>
      <title>Stop VM Negative</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/negative-stop-vm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/negative-stop-vm/</guid>
      <description> In a multi-node setup disconnect/shutdown the node where the VM is running Stop the VM  Expected Results  The VM list should quickly update to not running, or some other error state  </description>
    </item>
    
    <item>
      <title>Take host out of maintenance mode that has been rebooted</title>
      <link>https://harvester.github.io/tests/manual/hosts/maintenance-mode-enable-host-rebooted/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/maintenance-mode-enable-host-rebooted/</guid>
      <description> For host in maintenance mode that has been rebooted take host out of maintenance mode  Expected Results  Host should go to Active Label shbould go green  </description>
    </item>
    
    <item>
      <title>Take host out of maintenance mode that has not been rebooted</title>
      <link>https://harvester.github.io/tests/manual/hosts/maintenance-mode-enable-host-not-rebooted/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/maintenance-mode-enable-host-not-rebooted/</guid>
      <description> For host in maintenance mode that has not been rebooted take host out of maintenance mode  Expected Results  Host should go to Active Label shbould go green  </description>
    </item>
    
    <item>
      <title>Target Harvester by setting the variable kubeconfig with your kubeconfig file in the provider.tf file</title>
      <link>https://harvester.github.io/tests/manual/terraform-provider/harvester-kubeconfig-variasble/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraform-provider/harvester-kubeconfig-variasble/</guid>
      <description>Define the kubeconfig variable in the provider.tf file  terraform { required_providers { harvester = { source = &amp;quot;registry.terraform.io/harvester/harvester&amp;quot; version = &amp;quot;~&amp;gt; 0.1.0&amp;quot; } } } provider &amp;quot;harvester&amp;quot; { kubeconfig = &amp;quot;/path/of/my/kubeconfig&amp;quot; }  Check if you can interact with the Harvester by creating resource like a SSH key Execute the terraform apply command  Expected Results  The resource should be created Apply complete! Resources: 1 added, 0 changed, 0 destroyed.</description>
    </item>
    
    <item>
      <title>Target Harvester with the default kubeconfig located in $HOME/.kube/config</title>
      <link>https://harvester.github.io/tests/manual/terraform-provider/harvester-kubeconfig-home/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraform-provider/harvester-kubeconfig-home/</guid>
      <description> Make sure the kubeconfig is defined in the file $HOME/.kube/config Check if you can interact with the Harvester by creating resource like a SSH key Execute the terraform apply command  Expected Results  The resource should be created Apply complete! Resources: 1 added, 0 changed, 0 destroyed. Check if you can see your resource in the Harvester WebUI  </description>
    </item>
    
    <item>
      <title>Temporary network disruption</title>
      <link>https://harvester.github.io/tests/manual/hosts/negative-network-disruption/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/negative-network-disruption/</guid>
      <description> Create a vms on the cluster. Disable network of a node for sometime. e.g. 5 sec, 5 mins  Expected Results  VM should be accessible after the network is up.  </description>
    </item>
    
    <item>
      <title>Test a deployment with ALL resources at the same time</title>
      <link>https://harvester.github.io/tests/manual/terraform-provider/deployment-all-resources/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraform-provider/deployment-all-resources/</guid>
      <description>Re-use the previous generated TF files and group them all either in one directory or in the same file Generates a speculative execution plan with terraform plan command Create the resources with terraform apply command Check that all resources are correctly created/running on the Harvester cluster Destroy the resources with the command terraform destroy  Expected Results Refer to the harvester_ssh_key resource expected results</description>
    </item>
    
    <item>
      <title>Test aborting live migration</title>
      <link>https://harvester.github.io/tests/manual/live-migration/abort-live-migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/abort-live-migration/</guid>
      <description> On a VM that is turned on select migrate Start the migration Abort the migration  Expected Results  You should see the status move to migrating You should see the status move to aborting migration You should see the status move to running The VM should pass health checks  </description>
    </item>
    
    <item>
      <title>Test the harvester_clusternetwork resource</title>
      <link>https://harvester.github.io/tests/manual/terraform-provider/harvester-clusternetwork-resource/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraform-provider/harvester-clusternetwork-resource/</guid>
      <description>Refer to the harvester_ssh_key resource test steps</description>
    </item>
    
    <item>
      <title>Test the harvester_image resource</title>
      <link>https://harvester.github.io/tests/manual/terraform-provider/harvester-image-resource/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraform-provider/harvester-image-resource/</guid>
      <description>Refer to the harvester_ssh_key resource test steps</description>
    </item>
    
    <item>
      <title>Test the harvester_network resource</title>
      <link>https://harvester.github.io/tests/manual/terraform-provider/harvester-network-resource/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraform-provider/harvester-network-resource/</guid>
      <description>Refer to the harvester_ssh_key resource test steps</description>
    </item>
    
    <item>
      <title>Test the harvester_ssh_key resource</title>
      <link>https://harvester.github.io/tests/manual/terraform-provider/harvester-ssh-key-resource/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraform-provider/harvester-ssh-key-resource/</guid>
      <description>These following steps must be done for every resources, for avoiding repetitions, look at the detailed instructions at the beginning of the page.
 Import a resource Generates a speculative execution plan with terraform plan command Create the resource with terraform apply command Use terraform plan again Use terraform apply again Destroy the resource with the command terraform destroy  Expected Results  The resource is well imported in the terraform.</description>
    </item>
    
    <item>
      <title>Test the harvester_virtualmachine resource</title>
      <link>https://harvester.github.io/tests/manual/terraform-provider/harvester-virtualmachine-resource/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraform-provider/harvester-virtualmachine-resource/</guid>
      <description>Refer to the harvester_ssh_key resource test steps</description>
    </item>
    
    <item>
      <title>Test the harvester_volume resource</title>
      <link>https://harvester.github.io/tests/manual/terraform-provider/harvester-volume-resource/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/terraform-provider/harvester-volume-resource/</guid>
      <description>Refer to the harvester_ssh_key resource test steps</description>
    </item>
    
    <item>
      <title>Test zero downtime for live migration download test</title>
      <link>https://harvester.github.io/tests/manual/live-migration/zero-downtime-download-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/zero-downtime-download-test/</guid>
      <description> Connect to VM via console Start a large file download Live migrate VM to new host Verify that file download does not fail  Expected Results  Console should open VM should start to migrate File download should  </description>
    </item>
    
    <item>
      <title>Test zero downtime for live migration ping test</title>
      <link>https://harvester.github.io/tests/manual/live-migration/zero-downtime-ping-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/live-migration/zero-downtime-ping-test/</guid>
      <description> Continually ping VM Verify that ping is getting a response Live migrate VM to new host Verify that ping continues  Expected Results  Ping should get response VM should start to migrate Ping should not get any dropped packets  </description>
    </item>
    
    <item>
      <title>Try to add a network with no name</title>
      <link>https://harvester.github.io/tests/manual/network/negative-add-network-no-name/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/negative-add-network-no-name/</guid>
      <description> Navigate to the networks page in harvester Click Create Don&amp;rsquo;t add a name Add a VLAN ID Click Create  Expected Results  You should get an error that says you need to add a name  </description>
    </item>
    
    <item>
      <title>Turn off host that is in maintenance mode</title>
      <link>https://harvester.github.io/tests/manual/hosts/maintenance-mode-turn-off-host/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/maintenance-mode-turn-off-host/</guid>
      <description>Put host in maintenance mode Migrate VMs Wait for VMs to migrate Wait for any vms to migrate off Shut down Host  Expected Results  Host should start to go into maintenance mode Any VMs should migrate off Host should go into maintenance mode host should shut down Maintenance mode label in hosts list should go red  Known bugs https://github.com/harvester/harvester/issues/1272</description>
    </item>
    
    <item>
      <title>Upload Cloud Image</title>
      <link>https://harvester.github.io/tests/manual/images/upload-cloud-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/images/upload-cloud-image/</guid>
      <description> Upload image to images page Create new vm with image using appropriate template Run VM health checks  Expected Results  Image should upload Health checks should pass  </description>
    </item>
    
    <item>
      <title>Upload image that is invalid</title>
      <link>https://harvester.github.io/tests/manual/images/negative-upload-invalid-image-file/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/images/negative-upload-invalid-image-file/</guid>
      <description>steTry to upload invalid image file to images page  Something like dmg, or tar.gzps    Expected Results  You should get an error  Known Bugs https://github.com/harvester/harvester/issues/1425</description>
    </item>
    
    <item>
      <title>Upload ISO Image</title>
      <link>https://harvester.github.io/tests/manual/images/upload-iso-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/images/upload-iso-image/</guid>
      <description> Upload image to images page Create new vm with image using appropriate template Run VM health checks  Expected Results  Image should upload Health checks should pass  </description>
    </item>
    
    <item>
      <title>Use a non-admin user</title>
      <link>https://harvester.github.io/tests/manual/node-driver/non-admin-user/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/non-admin-user/</guid>
      <description>create harvester user ltang, password ltang add a harvester node template Refer to the &amp;ldquo;Test Data&amp;rdquo; value setting. Use this template to create the corresponding cluster  Expected Results  The status of the created cluster shows active The status of the corresponding vm on harvester active The information displayed on rancher and harvester matches the template configuration  Test Data Harvester Node Template HARVESTER OPTIONS  Account Access Internal Harvester Username:admin Password:admin Instance Options CPUs:2 Memorys:4 Disk:40 Bus:Virtlo/SATA/SCSI Image: openSUSE-Leap-15.</description>
    </item>
    
    <item>
      <title>Validate network connectivity external VLAN</title>
      <link>https://harvester.github.io/tests/manual/network/validate-network-external-vlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/validate-network-external-vlan/</guid>
      <description> Create a new VM Make sure that the network is set to the external VLAN with bridge as the type Ping VM Attempt to SSH to VM  Expected Results  VM should be created You should be able to ping the VM from an external network You should be able to SSH to VM  </description>
    </item>
    
    <item>
      <title>Validate network connectivity invalid external VLAN</title>
      <link>https://harvester.github.io/tests/manual/network/negative-network-connectivity-invalid-vlan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/negative-network-connectivity-invalid-vlan/</guid>
      <description> Create a new VM Make sure that the network is set to the external VLAN with bridge as the type and a VLAN ID that isn&amp;rsquo;t valid for your network Ping VM Attempt to SSH to VM  Expected Results  VM should be created You should not be able to ping the VM from an external network You should not be able to SSH to VM  </description>
    </item>
    
    <item>
      <title>Validate network connectivity management network</title>
      <link>https://harvester.github.io/tests/manual/network/validate-network-management-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/network/validate-network-management-network/</guid>
      <description> Create a new VM Make sure that the network is set to the management network with masquerade as the type Ping VM Attempt to SSH to VM  Expected Results  VM should be created You should not be able to ping the VM from an external network You should not be able to SSH to VM  </description>
    </item>
    
    <item>
      <title>Validate volume shows as in use when attached</title>
      <link>https://harvester.github.io/tests/manual/volumes/validate-volume-shows-in-use-while-attached/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/volumes/validate-volume-shows-in-use-while-attached/</guid>
      <description> Navigate to Volumes and check for a volume in use by a VM Verify that the state says In Use  Expected Results  State should show correctly  </description>
    </item>
    
    <item>
      <title>Verify &#34;Add Node Pool&#34;</title>
      <link>https://harvester.github.io/tests/manual/node-driver/verify-add-node-pool/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/node-driver/verify-add-node-pool/</guid>
      <description> Create a cluster of 3 nodes, One node with etcd, Control Plane, Worker, the other two with Worker The cluster is created successfully, use the command kubectl get node to view the node roles  Expected Results  The status of the created cluster shows active show the 3 created node status running in harvester&amp;rsquo;s vm list the information displayed on rancher and harvester matches the template configuration Check that the node role is correct  </description>
    </item>
    
    <item>
      <title>Verify and Configure Networking Connection</title>
      <link>https://harvester.github.io/tests/manual/deployment/verify-network-connection/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/verify-network-connection/</guid>
      <description>Provide the hostName Select management NIC bond Select the IPv4 (Automatic and Static)  Expected Results This value of hostname should be overwritten by DHCP if DHCP supplies a hostname for the system. If DHCP doesn&amp;rsquo;t offer a hostname and this value is empty, a random hostname will be generated.</description>
    </item>
    
    <item>
      <title>Verify Configuring SSH keys</title>
      <link>https://harvester.github.io/tests/manual/deployment/verify-ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/verify-ssh/</guid>
      <description>Provide SSH keys while installing the Harvester. Verify user is able to login the node using that ssh key.  Expected Results User should be able to login to the node using that ssh key.</description>
    </item>
    
    <item>
      <title>Verify Configuring via HTTP URL</title>
      <link>https://harvester.github.io/tests/manual/deployment/verify-http-config/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/verify-http-config/</guid>
      <description>Provide the remote Harvester config, you can find an example of the config I&amp;rsquo;m using in the deployment test plan description  Expected Results  Check that all values are taking into account  If you are using my config file, check: the node must be off after the installation the nvme and kvm modules are loaded the file /etc/test.txt exists with the correct rights the systcl values the env variable test_env should exist dns configured in /etc/resolv.</description>
    </item>
    
    <item>
      <title>Verify Enabling maintenance mode</title>
      <link>https://harvester.github.io/tests/manual/hosts/verify-enabling-maintenance-mode/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/verify-enabling-maintenance-mode/</guid>
      <description> Navigate to the Hosts page and select the node Click Maintenance Mode  Expected Results  The existing VM should get migrated to other nodes. Verify the CRDs to see the maintenance mode is enabled.  Comments  Needs other test cases to be added If VM migration fails How does live migration work What happens if there are no schedulable resources on nodes  Check CRDs on hosts  On going into maintenance mode kubectl get virtualmachines &amp;ndash;all-namespaces   Kubectl get virtualmachines/name -o yaml  On coming out of maintenance mode kubectl get virtualmachines &amp;ndash;all-namespaces     Kubectl get virtualmachines/name -o yaml  Check that maintenance mode host isn&amp;rsquo;t schedulable  Fully provision all nodes and try to create a VM     It should fail  Migration with maintenance mode What if migration gets stuck, can you cancel VMs going to different hosts Canceling maintenance mode P1  Put in maintenance mode Check migration of VMs Check status of VMs modify filesystem on VMs Check status of host Take host out of maintenance mode Check status of host Migrate VMs back to host Check filesystem Create new VMs on host Check status of VMs      </description>
    </item>
    
    <item>
      <title>Verify operations like Stop, restart, pause, download YAML, generate template</title>
      <link>https://harvester.github.io/tests/manual/virtual-machines/verify-operations-like-stop-restart-pause-download-yaml-generate-template/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/virtual-machines/verify-operations-like-stop-restart-pause-download-yaml-generate-template/</guid>
      <description> Take an existing VM and Press the appropriate buttons for the associated operations  Stop Restart Pause Download YAML Generate Template    Expected Results  All operations should complete successfully  </description>
    </item>
    
    <item>
      <title>Verify SSH key was added from Github during install</title>
      <link>https://harvester.github.io/tests/manual/authentication/verify-github-ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/authentication/verify-github-ssh/</guid>
      <description> Add ssh key from Github while installing the Harvester. Login Harvester with github.  Expected Results  User should be able to logout/login successfully.  </description>
    </item>
    
    <item>
      <title>Verify the external link at the bottom of the page</title>
      <link>https://harvester.github.io/tests/manual/ui/verify-bottom-links/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/ui/verify-bottom-links/</guid>
      <description>Click all the external links available at the bottom of the page - Docs, Forums, Slack, File an issue. Click the Generate support bundle at the bottom of the page  Expected Results  The external links should take user to correct URL in new tab in the browser. The support bundle should be generated once the Generate support bundle. The progress should be shown while the bundle is getting generated.</description>
    </item>
    
    <item>
      <title>Verify the Filter on the Host page</title>
      <link>https://harvester.github.io/tests/manual/hosts/verify-filter-on-host-page/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/verify-filter-on-host-page/</guid>
      <description> Enter name of a host and verify the nodes get filtered out.  Expected Results  The edited name should be reflected on the host.  </description>
    </item>
    
    <item>
      <title>Verify the Harvester UI URL</title>
      <link>https://harvester.github.io/tests/manual/ui/verify-url/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/ui/verify-url/</guid>
      <description> Navigate to the Harvester UI and verify the URL. Verify the Harvester icon on the left top corner  Expected Results  The URL should be the management ip + /dashboard redirect to login page if not login redirect to dashboard page if already login  </description>
    </item>
    
    <item>
      <title>Verify the info of the node</title>
      <link>https://harvester.github.io/tests/manual/hosts/verify-node-info/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/verify-node-info/</guid>
      <description> Navigate to the hosts tab and verify the following.  State Name Host IP CPU Memory Storage Size Age    Expected Results  All the data/status shown on the page should be correct.  </description>
    </item>
    
    <item>
      <title>Verify the installation confirmation screen</title>
      <link>https://harvester.github.io/tests/manual/deployment/verify-installation-confirmation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/verify-installation-confirmation/</guid>
      <description>Verify all the details shown on the screen  Expected Results The info should reflect all the user filled data.</description>
    </item>
    
    <item>
      <title>Verify the Installer Options</title>
      <link>https://harvester.github.io/tests/manual/deployment/verify-installer-options/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/verify-installer-options/</guid>
      <description> Verify the following options available while installing the Harvester is working  Installation target Cluster token Password VIP NTP Address    Expected Results  Should show all the disks available. Verify the min and max length acceptable for cluster token. Verify the password rule  </description>
    </item>
    
    <item>
      <title>Verify the left side menu</title>
      <link>https://harvester.github.io/tests/manual/ui/verify-left-menu/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/ui/verify-left-menu/</guid>
      <description> Check all the menu at the left side of the screen. Verify the preference and logout option is available at the right top of the screen  Expected Results  The menu should have Dashboard, Hosts, Virtual machines, Volumes, Images and Advance. The Advance menu should have sub menu Templates, backups, network, SSH keys, Users, Cloud config templates, Settings. Clicking on the menu should take user to the respective pages  </description>
    </item>
    
    <item>
      <title>Verify the links which navigate to the internal pages</title>
      <link>https://harvester.github.io/tests/manual/ui/verify-internal-links/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/ui/verify-internal-links/</guid>
      <description> Click the links available on the pages like on dashboard - host, virtual machines etc Verify the events and resources tabs presents in the pages e.g. - Dashboard, Virtual machines  Expected Results  The internal link should take user to the correct page in the same tab opened in the browser  </description>
    </item>
    
    <item>
      <title>Verify the options available for image</title>
      <link>https://harvester.github.io/tests/manual/images/verify-options-available-for-image/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/images/verify-options-available-for-image/</guid>
      <description> Create vm with YAML using the menu option. Download Yaml Verify the downloaded Yaml file. Clone the Image  Expected Results  All user-specified fields must match what show on GUI:  Namespace Name Description URL Labels    </description>
    </item>
    
    <item>
      <title>Verify the Proxy configuration</title>
      <link>https://harvester.github.io/tests/manual/deployment/verify-proxy/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/verify-proxy/</guid>
      <description>Provide a valid proxy address, verify it works after installation is complete. Provide empty proxy address.  Expected Results For empty proxy address, by default DHCP should provide the management url and it should navigate to the Harvester UI.</description>
    </item>
    
    <item>
      <title>Verify the state for Powered down node</title>
      <link>https://harvester.github.io/tests/manual/hosts/negative-verify-state-powered-down-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/hosts/negative-verify-state-powered-down-node/</guid>
      <description> Power down the node and check the state of the node in the cluster  Expected Results  The node state should show unavilable  </description>
    </item>
    
    <item>
      <title>VIP Load balancer verification</title>
      <link>https://harvester.github.io/tests/manual/deployment/verify-vip-load-balancer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/deployment/verify-vip-load-balancer/</guid>
      <description> Install Harvester on one Node  Install with VIP pulling from DHCP Verify that IP is assigned via DHCP    Add at least one additional node  Use VIP address as management address for adding node   Finish install of additional nodes Create new VM Connect to VM via web console  Expected Results  Install of all nodes should complete New nodes should show up in hosts list via web UI at VIP VMs should create Console should open  </description>
    </item>
    
    <item>
      <title>virtualmachineimages.harvesterhci.io</title>
      <link>https://harvester.github.io/tests/manual/webhooks/virtualmachineimages.harvesterhci.io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/webhooks/virtualmachineimages.harvesterhci.io/</guid>
      <description>GUI  Create an image from GUI Create another image with the same name. The operation should fail with admission webhook &amp;ldquo;validator.harvesterhci.io&amp;rdquo; denied the request: A resource with the same name exists  kube-api  Create an image from the manifest:  $ cat image.yaml --- apiVersion: harvesterhci.io/v1beta1 kind: VirtualMachineImage metadata: generateName: image- namespace: default spec: sourceType: download displayName: cirros-0.5.1-x86_64-disk2.img url: http://192.168.2.106/cirros-0.5.1-x86_64-disk.img $ kubectl create -f image.yml virtualmachineimage.harvesterhci.io/image-8dkbq created  Try to create an image with the same manifest:  $ kubectl create -f image.</description>
    </item>
    
    <item>
      <title>virtualmachinerestores.harvesterhci.io</title>
      <link>https://harvester.github.io/tests/manual/webhooks/virtualmachinerestores.harvesterhci.io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/webhooks/virtualmachinerestores.harvesterhci.io/</guid>
      <description>GUI  Setup a backup target Create a backup from a VM. Assume the VM name is vm-test Wait until backup is done Restore the backup to a VM, enter vm-test in the Virtual Machine Name field  kube-api $ cat restore.yaml 1 --- apiVersion: harvesterhci.io/v1beta1 kind: VirtualMachineRestore metadata: name: restore-aaaa namespace: default spec: newVM: false target: apiGroup: kubevirt.io kind: VirtualMachine name: &amp;quot;&amp;quot; virtualMachineBackupName: test $ kubectl create -f restore.yaml Expected Results GUI  The operation should fail with admission webhook &amp;ldquo;validator.</description>
    </item>
    
    <item>
      <title>virtualmachinetemplateversions.harvesterhci.io</title>
      <link>https://harvester.github.io/tests/manual/webhooks/virtualmachinetemplateversions.harvesterhci.io/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://harvester.github.io/tests/manual/webhooks/virtualmachinetemplateversions.harvesterhci.io/</guid>
      <description>kube-api  List default templates: $ kubectl get virtualmachinetemplateversions.harvesterhci.io -n harvester-public  GUI  Go to Advanced -&amp;gt; Templates page Create a new template and set it as the default version Try to delete the default version  Expected Results kube-api  Default templates should exist:  NAME TEMPLATE_ID VERSION AGE iso-image-base-version 1 39m raw-image-base-version 1 39m windows-iso-image-base-version 1 39m GUI  Creating a new template should succeed Deleting the default version of a template should fail with: admission webhook &amp;ldquo;validator.</description>
    </item>
    
  </channel>
</rss>
